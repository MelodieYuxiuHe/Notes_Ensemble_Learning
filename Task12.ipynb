{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does blending work?\n",
    "\n",
    "1) Test set + (Validation set + training set)\n",
    "\n",
    "2) Have models (MODEL1), train these models using the training set (The models can be different, e.g. tree, logistic model, XGBoost)\n",
    "\n",
    "3) Use MODEL1 on Test set and Val set, have the test_predidct and val_predict\n",
    "\n",
    "4) Have models (MODEL2), use validation prediction as a training set (use the predicted result from step 3, as training set)\n",
    "\n",
    "5) Predict using MODEL2 on the test_predict from step (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Test + Validation + Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training X: (5600, 2)\n",
      "The shape of training y: (5600,)\n",
      "The shape of test X: (2000, 2)\n",
      "The shape of test y: (2000,)\n",
      "The shape of validation X: (2400, 2)\n",
      "The shape of validation y: (2400,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, target = make_blobs(n_samples=10000, centers=2, random_state=1, cluster_std=1.0 )\n",
    "\n",
    "#Training set\n",
    "X_train1,X_test,y_train1,y_test = train_test_split(data, target, test_size=0.2,\n",
    "random_state=1)\n",
    "\n",
    "#Split the 'training set' into Traing and validation set\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train1, y_train1, test_size=0.3,\n",
    "random_state=1)\n",
    "\n",
    "print(\"The shape of training X:\",X_train.shape)\n",
    "print(\"The shape of training y:\",y_train.shape)\n",
    "print(\"The shape of test X:\",X_test.shape)\n",
    "print(\"The shape of test y:\",y_test.shape)\n",
    "print(\"The shape of validation X:\",X_val.shape)\n",
    "print(\"The shape of validation y:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Have models (MODEL1), train these models using the training set (SVM, KNN, Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#MODEL1\n",
    "#SVM + Random Forest + KNN\n",
    "clfs = [SVC(probability = True),RandomForestClassifier(n_estimators=5, n_jobs=-1,\n",
    "criterion='gini'),KNeighborsClassifier()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use MODEL1 on Test set and Val set, have the test_predidct and val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features = np.zeros((X_val.shape[0],len(clfs))) \n",
    "test_features = np.zeros((X_test.shape[0],len(clfs))) \n",
    "for i,clf in enumerate(clfs):\n",
    "    clf.fit(X_train,y_train)\n",
    "    val_feature = clf.predict_proba(X_val)[:, 1]\n",
    "    test_feature = clf.predict_proba(X_test)[:,1]\n",
    "    val_features[:,i] = val_feature\n",
    "    test_features[:,i] = test_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Set up MODEL2, use validation prediction as a training set (use the predicted result from step 3, as training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up MODEL2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Val_features is from STEP3, y_val also\n",
    "lr.fit(val_features,y_val)\n",
    "\n",
    "#Output the prediction result\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr,test_features,y_test,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Blending - IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training X: (84, 4)\n",
      "The shape of training y: (84,)\n",
      "The shape of test X: (30, 4)\n",
      "The shape of test y: (30,)\n",
      "The shape of validation X: (36, 4)\n",
      "The shape of validation y: (36,)\n"
     ]
    }
   ],
   "source": [
    "#Training set\n",
    "X_train1,X_test,y_train1,y_test = train_test_split(X, y, test_size=0.2,\n",
    "random_state=42)\n",
    "\n",
    "#Split the 'training set' into Traing and validation set\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train1, y_train1, test_size=0.3,\n",
    "random_state=42)\n",
    "\n",
    "print(\"The shape of training X:\",X_train.shape)\n",
    "print(\"The shape of training y:\",y_train.shape)\n",
    "print(\"The shape of test X:\",X_test.shape)\n",
    "print(\"The shape of test y:\",y_test.shape)\n",
    "print(\"The shape of validation X:\",X_val.shape)\n",
    "print(\"The shape of validation y:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#MODEL1\n",
    "#SVM + Random Forest + KNN\n",
    "clfs = [SVC(probability = True),RandomForestClassifier(n_estimators=2,\n",
    "criterion='gini'),KNeighborsClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features = np.zeros((X_val.shape[0],len(clfs))) \n",
    "test_features = np.zeros((X_test.shape[0],len(clfs))) \n",
    "for i,clf in enumerate(clfs):\n",
    "    clf.fit(X_train,y_train)\n",
    "    val_feature = clf.predict_proba(X_val)[:, 1]\n",
    "    test_feature = clf.predict_proba(X_test)[:,1]\n",
    "    val_features[:,i] = val_feature\n",
    "    test_features[:,i] = test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.21817084, -0.08757105, -0.14423259])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Val_features is from STEP3, y_val also\n",
    "lr.fit(val_features,y_val)\n",
    "\n",
    "#Output the prediction result\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr,test_features,y_test,cv=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
