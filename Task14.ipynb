{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of 'Happiness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error,mean_absolute_error, f1_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "from sklearn.linear_model import BayesianRidge as br\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.linear_model import ElasticNet as en\n",
    "from sklearn.kernel_ridge import KernelRidge as kr\n",
    "from sklearn.model_selection import  KFold, StratifiedKFold,GroupKFold, RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/Melodie/Downloads/2021Spring/Study/DataWhale/April_Ensembled_Learning/Notes_Ensemble_Learning/Data/case_1/train.csv\", parse_dates=['survey_time'],encoding='latin-1') \n",
    "test = pd.read_csv(\"/Users/Melodie/Downloads/2021Spring/Study/DataWhale/April_Ensembled_Learning/Notes_Ensemble_Learning/Data/case_1/test.csv\", parse_dates=['survey_time'],encoding='latin-1') #latin-1向下兼容ASCII\n",
    "\n",
    "#Remove the 'happiness' variable\n",
    "train = train[train[\"happiness\"]!=-8].reset_index(drop=True)\n",
    "train_data_copy = train.copy() \n",
    "\n",
    "#'Happiness' variable\n",
    "target_col = \"happiness\" \n",
    "target = train_data_copy[target_col]\n",
    "del train_data_copy[target_col] \n",
    "\n",
    "data = pd.concat([train_data_copy,test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA 'Happiness' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7988.000000\n",
       "mean        3.867927\n",
       "std         0.818717\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         4.000000\n",
       "75%         4.000000\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.happiness.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'survey_type', 'province', 'city', 'county', 'survey_time',\n",
       "       'gender', 'birth', 'nationality', 'religion',\n",
       "       ...\n",
       "       'neighbor_familiarity', 'public_service_1', 'public_service_2',\n",
       "       'public_service_3', 'public_service_4', 'public_service_5',\n",
       "       'public_service_6', 'public_service_7', 'public_service_8',\n",
       "       'public_service_9'],\n",
       "      dtype='object', length=139)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some negative values. We wants to figure out how many such negative values in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getres1(row):\n",
    "    return len([x for x in row.values if type(x)==int and x<0])\n",
    "\n",
    "def getres2(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-8])\n",
    "\n",
    "def getres3(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-1])\n",
    "\n",
    "def getres4(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-2])\n",
    "\n",
    "def getres5(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-3])\n",
    "\n",
    "data['neg1'] = data[data.columns].apply(lambda row:getres1(row),axis=1)\n",
    "data['neg2'] = data[data.columns].apply(lambda row:getres2(row),axis=1)\n",
    "data['neg3'] = data[data.columns].apply(lambda row:getres3(row),axis=1)\n",
    "data['neg4'] = data[data.columns].apply(lambda row:getres4(row),axis=1)\n",
    "data['neg5'] = data[data.columns].apply(lambda row:getres5(row),axis=1)\n",
    "\n",
    "#When there are more than 20 negative values in one observation, we set it to be 20 (Why?)\n",
    "data.loc[data['neg1']>20,'neg1'] = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data['work_status'] = data['work_status'].fillna(0)\n",
    "data['work_yr'] = data['work_yr'].fillna(0)\n",
    "data['work_manage'] = data['work_manage'].fillna(0)\n",
    "data['work_type'] = data['work_type'].fillna(0)\n",
    "\n",
    "data['edu_yr'] = data['edu_yr'].fillna(0)\n",
    "data['edu_status'] = data['edu_status'].fillna(0)\n",
    "\n",
    "data['s_work_type'] = data['s_work_type'].fillna(0)\n",
    "data['s_work_status'] = data['s_work_status'].fillna(0)\n",
    "data['s_political'] = data['s_political'].fillna(0)\n",
    "data['s_hukou'] = data['s_hukou'].fillna(0)\n",
    "data['s_income'] = data['s_income'].fillna(0)\n",
    "data['s_birth'] = data['s_birth'].fillna(0)\n",
    "data['s_edu'] = data['s_edu'].fillna(0)\n",
    "data['s_work_exper'] = data['s_work_exper'].fillna(0)\n",
    "\n",
    "data['minor_child'] = data['minor_child'].fillna(0)\n",
    "data['marital_now'] = data['marital_now'].fillna(0)\n",
    "data['marital_1st'] = data['marital_1st'].fillna(0)\n",
    "data['social_neighbor']=data['social_neighbor'].fillna(0)\n",
    "data['social_friend']=data['social_friend'].fillna(0)\n",
    "data['hukou_loc']=data['hukou_loc'].fillna(1) \n",
    "#Use mean to fill\n",
    "data['family_income']=data['family_income'].fillna(66365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survey_time'] = pd.to_datetime(data['survey_time'], format='%Y-%m-%d',errors='coerce')\n",
    "data['survey_time'] = data['survey_time'].dt.year\n",
    "#The age while doing the survey\n",
    "data['age'] = data['survey_time']-data['birth']\n",
    "\n",
    "#Categorize the age to be 6 categories: 0-17/18-26/27-34/....\n",
    "bins = [0,17,26,34,50,63,100]\n",
    "data['age_bin'] = pd.cut(data['age'], bins, labels=[0,1,2,3,4,5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: when dealing with the missing value, here used some subjective standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['height_cm'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Religion, if less than 0 - no religion\n",
    "data.loc[data['religion']<0,'religion'] = 1 \n",
    "data.loc[data['religion_freq']<0,'religion_freq'] = 1 \n",
    "\n",
    "#Education level - if less than 0, set to be middle school. (But there are people especially cohort born before 1950, it is likely that their highest education level is primary school)\n",
    "data.loc[data['edu']<0,'edu'] = 4 #Middle school\n",
    "data.loc[data['edu_status']<0,'edu_status'] = 0\n",
    "data.loc[data['edu_yr']<0,'edu_yr'] = 0\n",
    "\n",
    "#Why there are negative value for income? 'Prefer not to say' or 'no income'?\n",
    "data.loc[data['income']<0,'income'] = 0 \n",
    "\n",
    "data.loc[data['political']<0,'political'] = 1 #Default not in the party\n",
    "\n",
    "\n",
    "data.loc[(data['weight_jin']<=80)&(data['height_cm']>=160),'weight_jin']= data['weight_jin']*2\n",
    "# data.loc[data['weight_jin']<=60,'weight_jin']= data['weight_jin']*2  #Data integrity\n",
    "\n",
    "# Minimum value of height_cm is 100, which makes sense\n",
    "# data.loc[data['height_cm']<150,'height_cm'] = 150 \n",
    "\n",
    "#Health\n",
    "data.loc[data['health']<0,'health'] = 3 \n",
    "data.loc[data['health_problem']<0,'health_problem'] = 3\n",
    "\n",
    "data.loc[data['depression']<0,'depression'] = 3 \n",
    "\n",
    "data.loc[data['media_1']<0,'media_1'] = 1 \n",
    "data.loc[data['media_2']<0,'media_2'] = 1\n",
    "data.loc[data['media_3']<0,'media_3'] = 1\n",
    "data.loc[data['media_4']<0,'media_4'] = 1\n",
    "data.loc[data['media_5']<0,'media_5'] = 1\n",
    "data.loc[data['media_6']<0,'media_6'] = 1\n",
    "\n",
    "data.loc[data['leisure_1']<0,'leisure_1'] = 1 \n",
    "data.loc[data['leisure_2']<0,'leisure_2'] = 5\n",
    "data.loc[data['leisure_3']<0,'leisure_3'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing value in categorical data - mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['leisure_4']<0,'leisure_4'] = data['leisure_4'].mode() \n",
    "data.loc[data['leisure_5']<0,'leisure_5'] = data['leisure_5'].mode()\n",
    "data.loc[data['leisure_6']<0,'leisure_6'] = data['leisure_6'].mode()\n",
    "data.loc[data['leisure_7']<0,'leisure_7'] = data['leisure_7'].mode()\n",
    "data.loc[data['leisure_8']<0,'leisure_8'] = data['leisure_8'].mode()\n",
    "data.loc[data['leisure_9']<0,'leisure_9'] = data['leisure_9'].mode()\n",
    "data.loc[data['leisure_10']<0,'leisure_10'] = data['leisure_10'].mode()\n",
    "data.loc[data['leisure_11']<0,'leisure_11'] = data['leisure_11'].mode()\n",
    "data.loc[data['leisure_12']<0,'leisure_12'] = data['leisure_12'].mode()\n",
    "data.loc[data['socialize']<0,'socialize'] = data['socialize'].mode()\n",
    "data.loc[data['relax']<0,'relax'] = data['relax'].mode()\n",
    "data.loc[data['learn']<0,'learn'] = data['learn'].mode()\n",
    "\n",
    "data.loc[data['social_neighbor']<0,'social_neighbor'] = 0\n",
    "data.loc[data['social_friend']<0,'social_friend'] = 0\n",
    "data.loc[data['socia_outing']<0,'socia_outing'] = 1\n",
    "data.loc[data['neighbor_familiarity']<0,'neighbor_familiarity']= 4\n",
    "\n",
    "data.loc[data['equity']<0,'equity'] = 4\n",
    "\n",
    "data.loc[data['class_10_before']<0,'class_10_before'] = 3\n",
    "data.loc[data['class']<0,'class'] = 5\n",
    "data.loc[data['class_10_after']<0,'class_10_after'] = 5\n",
    "data.loc[data['class_14']<0,'class_14'] = 2\n",
    "\n",
    "data.loc[data['work_status']<0,'work_status'] = 0\n",
    "data.loc[data['work_yr']<0,'work_yr'] = 0\n",
    "data.loc[data['work_manage']<0,'work_manage'] = 0\n",
    "data.loc[data['work_type']<0,'work_type'] = 0\n",
    "\n",
    "data.loc[data['insur_1']<0,'insur_1'] = 1\n",
    "data.loc[data['insur_2']<0,'insur_2'] = 1\n",
    "data.loc[data['insur_3']<0,'insur_3'] = 1\n",
    "data.loc[data['insur_4']<0,'insur_4'] = 1\n",
    "data.loc[data['insur_1']==0,'insur_1'] = 0\n",
    "data.loc[data['insur_2']==0,'insur_2'] = 0\n",
    "data.loc[data['insur_3']==0,'insur_3'] = 0\n",
    "data.loc[data['insur_4']==0,'insur_4'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing continuous data - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72464.02361969305"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['family_income'] >=0]['family_income'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['family_income']<0,'family_income'] = data[data['family_income'] >=0]['family_income'].mean()\n",
    "data.loc[data['family_m']<0,'family_m'] = 1\n",
    "data.loc[data['family_status']<0,'family_status'] = data['family_status'].mode()\n",
    "data.loc[data['house']<0,'house'] = 1\n",
    "data.loc[data['car']<0,'car'] = 0\n",
    "data.loc[data['car']==2,'car'] = 0 \n",
    "data.loc[data['son']<0,'son'] = 0\n",
    "data.loc[data['daughter']<0,'daughter'] = 0\n",
    "data.loc[data['minor_child']<0,'minor_child'] = 0\n",
    "\n",
    "data.loc[data['marital_1st']<0,'marital_1st'] = 0\n",
    "data.loc[data['marital_now']<0,'marital_now'] = 0\n",
    "\n",
    "data.loc[data['s_birth']<0,'s_birth'] = 0\n",
    "data.loc[data['s_edu']<0,'s_edu'] = 0\n",
    "data.loc[data['s_political']<0,'s_political'] = 0\n",
    "data.loc[data['s_hukou']<0,'s_hukou'] = 0\n",
    "data.loc[data['s_income']<0,'s_income'] = 0\n",
    "data.loc[data['s_work_type']<0,'s_work_type'] = 0\n",
    "data.loc[data['s_work_status']<0,'s_work_status'] = 0\n",
    "data.loc[data['s_work_exper']<0,'s_work_exper'] = 0\n",
    "\n",
    "data.loc[data['f_birth']<0,'f_birth'] = data[data['f_birth'] >=0]['f_birth'].mean()\n",
    "data.loc[data['f_edu']<0,'f_edu'] = 1\n",
    "data.loc[data['f_political']<0,'f_political'] = 1\n",
    "data.loc[data['f_work_14']<0,'f_work_14'] = 2\n",
    "data.loc[data['m_birth']<0,'m_birth'] = data[data['m_birth'] >=0]['m_birth'].mean()\n",
    "data.loc[data['m_edu']<0,'m_edu'] = 1\n",
    "data.loc[data['m_political']<0,'m_political'] = 1\n",
    "data.loc[data['m_work_14']<0,'m_work_14'] = 2\n",
    "\n",
    "data.loc[data['status_peer']<0,'status_peer'] = 2\n",
    "\n",
    "data.loc[data['status_3_before']<0,'status_3_before'] = 2\n",
    "\n",
    "data.loc[data['view']<0,'view'] = data[data['view'] >=0]['view'].mean()\n",
    "\n",
    "data.loc[data['inc_ability']<=0,'inc_ability']= data[data['inc_ability'] >=0]['inc_ability'].mean()\n",
    "\n",
    "data.loc[data['inc_exp']<=0,'inc_exp']= data[data['inc_exp'] >=0]['inc_exp'].mean()\n",
    "\n",
    "for i in range(1,9+1):\n",
    "    data.loc[data['public_service_'+str(i)]<0,'public_service_'+str(i)] = data['public_service_'+str(i)].dropna().mode().values\n",
    "for i in range(1,13+1):\n",
    "    data.loc[data['trust_'+str(i)]<0,'trust_'+str(i)] = data['trust_'+str(i)].dropna().mode().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['marital_1stbir'] = data['marital_1st'] - data['birth'] \n",
    "\n",
    "data['marital_nowtbir'] = data['marital_now'] - data['birth'] \n",
    "\n",
    "data['mar'] = data['marital_nowtbir'] - data['marital_1stbir']\n",
    "\n",
    "data['marital_sbir'] = data['marital_now']-data['s_birth']\n",
    "\n",
    "data['age_'] = data['marital_nowtbir'] - data['marital_sbir'] \n",
    "\n",
    "\n",
    "data['income/s_income'] = data['income']/(data['s_income']+1)\n",
    "data['income+s_income'] = data['income']+(data['s_income']+1)\n",
    "data['income/family_income'] = data['income']/(data['family_income']+1)\n",
    "data['all_income/family_income'] = (data['income']+data['s_income'])/(data['family_income']+1)\n",
    "data['income/inc_exp'] = data['income']/(data['inc_exp']+1)\n",
    "data['family_income/m'] = data['family_income']/(data['family_m']+0.01)\n",
    "data['income/m'] = data['income']/(data['family_m']+0.01)\n",
    "\n",
    "data['income/floor_area'] = data['income']/(data['floor_area']+0.01)\n",
    "data['all_income/floor_area'] = (data['income']+data['s_income'])/(data['floor_area']+0.01)\n",
    "data['family_income/floor_area'] = data['family_income']/(data['floor_area']+0.01)\n",
    "data['floor_area/m'] = data['floor_area']/(data['family_m']+0.01)\n",
    "\n",
    "data['class_10_diff'] = (data['class_10_after'] - data['class'])\n",
    "data['class_diff'] = data['class'] - data['class_10_before']\n",
    "data['class_14_diff'] = data['class'] - data['class_14']\n",
    "\n",
    "leisure_fea_lis = ['leisure_'+str(i) for i in range(1,13)]\n",
    "data['leisure_sum'] = data[leisure_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "public_service_fea_lis = ['public_service_'+str(i) for i in range(1,10)]\n",
    "data['public_service_sum'] = data[public_service_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "trust_fea_lis = ['trust_'+str(i) for i in range(1,14)]\n",
    "data['trust_sum'] = data[trust_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "data['province_income_mean'] = data.groupby(['province'])['income'].transform('mean').values\n",
    "data['province_family_income_mean'] = data.groupby(['province'])['family_income'].transform('mean').values\n",
    "data['province_equity_mean'] = data.groupby(['province'])['equity'].transform('mean').values\n",
    "data['province_depression_mean'] = data.groupby(['province'])['depression'].transform('mean').values\n",
    "data['province_floor_area_mean'] = data.groupby(['province'])['floor_area'].transform('mean').values\n",
    "data['province_health_mean'] = data.groupby(['province'])['health'].transform('mean').values\n",
    "data['province_class_10_diff_mean'] = data.groupby(['province'])['class_10_diff'].transform('mean').values\n",
    "data['province_class_mean'] = data.groupby(['province'])['class'].transform('mean').values\n",
    "data['province_health_problem_mean'] = data.groupby(['province'])['health_problem'].transform('mean').values\n",
    "data['province_family_status_mean'] = data.groupby(['province'])['family_status'].transform('mean').values\n",
    "data['province_leisure_sum_mean'] = data.groupby(['province'])['leisure_sum'].transform('mean').values\n",
    "data['province_public_service_sum_mean'] = data.groupby(['province'])['public_service_sum'].transform('mean').values\n",
    "data['province_trust_sum_mean'] = data.groupby(['province'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#city   mean 181+13=194\n",
    "data['city_income_mean'] = data.groupby(['city'])['income'].transform('mean').values #按照city分组\n",
    "data['city_family_income_mean'] = data.groupby(['city'])['family_income'].transform('mean').values\n",
    "data['city_equity_mean'] = data.groupby(['city'])['equity'].transform('mean').values\n",
    "data['city_depression_mean'] = data.groupby(['city'])['depression'].transform('mean').values\n",
    "data['city_floor_area_mean'] = data.groupby(['city'])['floor_area'].transform('mean').values\n",
    "data['city_health_mean'] = data.groupby(['city'])['health'].transform('mean').values\n",
    "data['city_class_10_diff_mean'] = data.groupby(['city'])['class_10_diff'].transform('mean').values\n",
    "data['city_class_mean'] = data.groupby(['city'])['class'].transform('mean').values\n",
    "data['city_health_problem_mean'] = data.groupby(['city'])['health_problem'].transform('mean').values\n",
    "data['city_family_status_mean'] = data.groupby(['city'])['family_status'].transform('mean').values\n",
    "data['city_leisure_sum_mean'] = data.groupby(['city'])['leisure_sum'].transform('mean').values\n",
    "data['city_public_service_sum_mean'] = data.groupby(['city'])['public_service_sum'].transform('mean').values\n",
    "data['city_trust_sum_mean'] = data.groupby(['city'])['trust_sum'].transform('mean').values\n",
    "\n",
    "data['county_income_mean'] = data.groupby(['county'])['income'].transform('mean').values\n",
    "data['county_family_income_mean'] = data.groupby(['county'])['family_income'].transform('mean').values\n",
    "data['county_equity_mean'] = data.groupby(['county'])['equity'].transform('mean').values\n",
    "data['county_depression_mean'] = data.groupby(['county'])['depression'].transform('mean').values\n",
    "data['county_floor_area_mean'] = data.groupby(['county'])['floor_area'].transform('mean').values\n",
    "data['county_health_mean'] = data.groupby(['county'])['health'].transform('mean').values\n",
    "data['county_class_10_diff_mean'] = data.groupby(['county'])['class_10_diff'].transform('mean').values\n",
    "data['county_class_mean'] = data.groupby(['county'])['class'].transform('mean').values\n",
    "data['county_health_problem_mean'] = data.groupby(['county'])['health_problem'].transform('mean').values\n",
    "data['county_family_status_mean'] = data.groupby(['county'])['family_status'].transform('mean').values\n",
    "data['county_leisure_sum_mean'] = data.groupby(['county'])['leisure_sum'].transform('mean').values\n",
    "data['county_public_service_sum_mean'] = data.groupby(['county'])['public_service_sum'].transform('mean').values\n",
    "data['county_trust_sum_mean'] = data.groupby(['county'])['trust_sum'].transform('mean').values\n",
    "\n",
    "data['income/province'] = data['income']/(data['province_income_mean'])                                      \n",
    "data['family_income/province'] = data['family_income']/(data['province_family_income_mean'])   \n",
    "data['equity/province'] = data['equity']/(data['province_equity_mean'])       \n",
    "data['depression/province'] = data['depression']/(data['province_depression_mean'])                                                \n",
    "data['floor_area/province'] = data['floor_area']/(data['province_floor_area_mean'])\n",
    "data['health/province'] = data['health']/(data['province_health_mean'])\n",
    "data['class_10_diff/province'] = data['class_10_diff']/(data['province_class_10_diff_mean'])\n",
    "data['class/province'] = data['class']/(data['province_class_mean'])\n",
    "data['health_problem/province'] = data['health_problem']/(data['province_health_problem_mean'])\n",
    "data['family_status/province'] = data['family_status']/(data['province_family_status_mean'])\n",
    "data['leisure_sum/province'] = data['leisure_sum']/(data['province_leisure_sum_mean'])\n",
    "data['public_service_sum/province'] = data['public_service_sum']/(data['province_public_service_sum_mean'])\n",
    "data['trust_sum/province'] = data['trust_sum']/(data['province_trust_sum_mean']+1)\n",
    "\n",
    "data['income/city'] = data['income']/(data['city_income_mean'])                                      \n",
    "data['family_income/city'] = data['family_income']/(data['city_family_income_mean'])   \n",
    "data['equity/city'] = data['equity']/(data['city_equity_mean'])       \n",
    "data['depression/city'] = data['depression']/(data['city_depression_mean'])                                                \n",
    "data['floor_area/city'] = data['floor_area']/(data['city_floor_area_mean'])\n",
    "data['health/city'] = data['health']/(data['city_health_mean'])\n",
    "data['class_10_diff/city'] = data['class_10_diff']/(data['city_class_10_diff_mean'])\n",
    "data['class/city'] = data['class']/(data['city_class_mean'])\n",
    "data['health_problem/city'] = data['health_problem']/(data['city_health_problem_mean'])\n",
    "data['family_status/city'] = data['family_status']/(data['city_family_status_mean'])\n",
    "data['leisure_sum/city'] = data['leisure_sum']/(data['city_leisure_sum_mean'])\n",
    "data['public_service_sum/city'] = data['public_service_sum']/(data['city_public_service_sum_mean'])\n",
    "data['trust_sum/city'] = data['trust_sum']/(data['city_trust_sum_mean'])\n",
    "\n",
    "\n",
    "data['income/county'] = data['income']/(data['county_income_mean'])                                      \n",
    "data['family_income/county'] = data['family_income']/(data['county_family_income_mean'])   \n",
    "data['equity/county'] = data['equity']/(data['county_equity_mean'])       \n",
    "data['depression/county'] = data['depression']/(data['county_depression_mean'])                                                \n",
    "data['floor_area/county'] = data['floor_area']/(data['county_floor_area_mean'])\n",
    "data['health/county'] = data['health']/(data['county_health_mean'])\n",
    "data['class_10_diff/county'] = data['class_10_diff']/(data['county_class_10_diff_mean'])\n",
    "data['class/county'] = data['class']/(data['county_class_mean'])\n",
    "data['health_problem/county'] = data['health_problem']/(data['county_health_problem_mean'])\n",
    "data['family_status/county'] = data['family_status']/(data['county_family_status_mean'])\n",
    "data['leisure_sum/county'] = data['leisure_sum']/(data['county_leisure_sum_mean'])\n",
    "data['public_service_sum/county'] = data['public_service_sum']/(data['county_public_service_sum_mean'])\n",
    "data['trust_sum/county'] = data['trust_sum']/(data['county_trust_sum_mean'])\n",
    "\n",
    "\n",
    "data['age_income_mean'] = data.groupby(['age'])['income'].transform('mean').values\n",
    "data['age_family_income_mean'] = data.groupby(['age'])['family_income'].transform('mean').values\n",
    "data['age_equity_mean'] = data.groupby(['age'])['equity'].transform('mean').values\n",
    "data['age_depression_mean'] = data.groupby(['age'])['depression'].transform('mean').values\n",
    "data['age_floor_area_mean'] = data.groupby(['age'])['floor_area'].transform('mean').values\n",
    "data['age_health_mean'] = data.groupby(['age'])['health'].transform('mean').values\n",
    "data['age_class_10_diff_mean'] = data.groupby(['age'])['class_10_diff'].transform('mean').values\n",
    "data['age_class_mean'] = data.groupby(['age'])['class'].transform('mean').values\n",
    "data['age_health_problem_mean'] = data.groupby(['age'])['health_problem'].transform('mean').values\n",
    "data['age_family_status_mean'] = data.groupby(['age'])['family_status'].transform('mean').values\n",
    "data['age_leisure_sum_mean'] = data.groupby(['age'])['leisure_sum'].transform('mean').values\n",
    "data['age_public_service_sum_mean'] = data.groupby(['age'])['public_service_sum'].transform('mean').values\n",
    "data['age_trust_sum_mean'] = data.groupby(['age'])['trust_sum'].transform('mean').values\n",
    "\n",
    "\n",
    "data['income/age'] = data['income']/(data['age_income_mean'])                                      \n",
    "data['family_income/age'] = data['family_income']/(data['age_family_income_mean'])   \n",
    "data['equity/age'] = data['equity']/(data['age_equity_mean'])       \n",
    "data['depression/age'] = data['depression']/(data['age_depression_mean'])                                                \n",
    "data['floor_area/age'] = data['floor_area']/(data['age_floor_area_mean'])\n",
    "data['health/age'] = data['health']/(data['age_health_mean'])\n",
    "data['class_10_diff/age'] = data['class_10_diff']/(data['age_class_10_diff_mean'])\n",
    "data['class/age'] = data['class']/(data['age_class_mean'])\n",
    "data['health_problem/age'] = data['health_problem']/(data['age_health_problem_mean'])\n",
    "data['family_status/age'] = data['family_status']/(data['age_family_status_mean'])\n",
    "data['leisure_sum/age'] = data['leisure_sum']/(data['age_leisure_sum_mean'])\n",
    "data['public_service_sum/age'] = data['public_service_sum']/(data['age_public_service_sum_mean'])\n",
    "data['trust_sum/age'] = data['trust_sum']/(data['age_trust_sum_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (10956, 272)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey_type</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>survey_time</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>depression/age</th>\n",
       "      <th>floor_area/age</th>\n",
       "      <th>health/age</th>\n",
       "      <th>class_10_diff/age</th>\n",
       "      <th>class/age</th>\n",
       "      <th>health_problem/age</th>\n",
       "      <th>family_status/age</th>\n",
       "      <th>leisure_sum/age</th>\n",
       "      <th>public_service_sum/age</th>\n",
       "      <th>trust_sum/age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>59</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285211</td>\n",
       "      <td>0.410351</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683307</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.724620</td>\n",
       "      <td>0.666638</td>\n",
       "      <td>0.925941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.952824</td>\n",
       "      <td>1.179337</td>\n",
       "      <td>1.012552</td>\n",
       "      <td>1.344444</td>\n",
       "      <td>0.892989</td>\n",
       "      <td>1.359551</td>\n",
       "      <td>1.011792</td>\n",
       "      <td>1.130778</td>\n",
       "      <td>1.188442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>126</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343537</td>\n",
       "      <td>0.972328</td>\n",
       "      <td>1.150485</td>\n",
       "      <td>1.190955</td>\n",
       "      <td>1.195762</td>\n",
       "      <td>1.055679</td>\n",
       "      <td>1.192893</td>\n",
       "      <td>0.966470</td>\n",
       "      <td>1.193204</td>\n",
       "      <td>0.803693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111663</td>\n",
       "      <td>0.642329</td>\n",
       "      <td>1.276353</td>\n",
       "      <td>4.977778</td>\n",
       "      <td>1.199143</td>\n",
       "      <td>1.188329</td>\n",
       "      <td>1.166078</td>\n",
       "      <td>0.899346</td>\n",
       "      <td>1.153810</td>\n",
       "      <td>1.300950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.587284</td>\n",
       "      <td>1.177106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>1.116803</td>\n",
       "      <td>1.093645</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>0.728161</td>\n",
       "      <td>1.117428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  survey_type  province  city  county  survey_time  gender  birth  \\\n",
       "0   1            1        12    32      59         2015       1   1959   \n",
       "1   2            2        18    52      85         2015       1   1992   \n",
       "2   3            2        29    83     126         2015       2   1967   \n",
       "3   4            2        10    28      51         2015       2   1943   \n",
       "4   5            1         7    18      36         2015       2   1994   \n",
       "\n",
       "   nationality  religion  ...  depression/age  floor_area/age health/age  \\\n",
       "0            1         1  ...        1.285211        0.410351   0.848837   \n",
       "1            1         1  ...        0.733333        0.952824   1.179337   \n",
       "2            1         0  ...        1.343537        0.972328   1.150485   \n",
       "3            1         1  ...        1.111663        0.642329   1.276353   \n",
       "4            1         1  ...        0.750000        0.587284   1.177106   \n",
       "\n",
       "   class_10_diff/age  class/age  health_problem/age  family_status/age  \\\n",
       "0           0.000000   0.683307            0.521429           0.734177   \n",
       "1           1.012552   1.344444            0.892989           1.359551   \n",
       "2           1.190955   1.195762            1.055679           1.192893   \n",
       "3           4.977778   1.199143            1.188329           1.166078   \n",
       "4           0.000000   0.236957            1.116803           1.093645   \n",
       "\n",
       "   leisure_sum/age  public_service_sum/age  trust_sum/age  \n",
       "0         0.724620                0.666638       0.925941  \n",
       "1         1.011792                1.130778       1.188442  \n",
       "2         0.966470                1.193204       0.803693  \n",
       "3         0.899346                1.153810       1.300950  \n",
       "4         1.045313                0.728161       1.117428  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape',data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 263)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_list=['id','survey_time','edu_other','invest_other','property_other','join_party','province','city','county']\n",
    "use_feature = [clo for clo in data.columns if clo not in del_list]\n",
    "data.fillna(0,inplace=True) \n",
    "train_shape = train.shape[0] \n",
    "features = data[use_feature].columns \n",
    "X_train_263 = data[:train_shape][use_feature].values\n",
    "y_train = target\n",
    "X_test_263 = data[train_shape:][use_feature].values\n",
    "X_train_263.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49 important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 49)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_fea_49 = ['equity','depression','health','class','family_status','health_problem','class_10_after',\n",
    "           'equity/province','equity/city','equity/county',\n",
    "           'depression/province','depression/city','depression/county',\n",
    "           'health/province','health/city','health/county',\n",
    "           'class/province','class/city','class/county',\n",
    "           'family_status/province','family_status/city','family_status/county',\n",
    "           'family_income/province','family_income/city','family_income/county',\n",
    "           'floor_area/province','floor_area/city','floor_area/county',\n",
    "           'leisure_sum/province','leisure_sum/city','leisure_sum/county',\n",
    "           'public_service_sum/province','public_service_sum/city','public_service_sum/county',\n",
    "           'trust_sum/province','trust_sum/city','trust_sum/county',\n",
    "           'income/m','public_service_sum','class_diff','status_3_before','age_income_mean','age_floor_area_mean',\n",
    "           'weight_jin','height_cm',\n",
    "           'health/age','depression/age','equity/age','leisure_sum/age'\n",
    "          ]\n",
    "train_shape = train.shape[0]\n",
    "X_train_49 = data[:train_shape][imp_fea_49].values\n",
    "X_test_49 = data[train_shape:][imp_fea_49].values\n",
    "X_train_49.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 383)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_fea = ['survey_type','gender','nationality','edu_status','political','hukou','hukou_loc','work_exper','work_status','work_type',\n",
    "           'work_manage','marital','s_political','s_hukou','s_work_exper','s_work_status','s_work_type','f_political','f_work_14',\n",
    "           'm_political','m_work_14'] \n",
    "noc_fea = [clo for clo in use_feature if clo not in cat_fea]\n",
    "\n",
    "onehot_data = data[cat_fea].values\n",
    "enc = preprocessing.OneHotEncoder(categories = 'auto')\n",
    "oh_data=enc.fit_transform(onehot_data).toarray()\n",
    "oh_data.shape \n",
    "\n",
    "X_train_oh = oh_data[:train_shape,:]\n",
    "X_test_oh = oh_data[train_shape:,:]\n",
    "X_train_oh.shape \n",
    "\n",
    "X_train_383 = np.column_stack([data[:train_shape][noc_fea].values,X_train_oh])\n",
    "X_test_383 = np.column_stack([data[train_shape:][noc_fea].values,X_test_oh])\n",
    "X_train_383.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - 263 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LightGBM - 5 fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.500907\tvalid_1's l2: 0.52984\n",
      "[1000]\ttraining's l2: 0.452352\tvalid_1's l2: 0.496366\n",
      "[1500]\ttraining's l2: 0.426069\tvalid_1's l2: 0.482754\n",
      "[2000]\ttraining's l2: 0.407771\tvalid_1's l2: 0.476582\n",
      "[2500]\ttraining's l2: 0.393323\tvalid_1's l2: 0.473025\n",
      "[3000]\ttraining's l2: 0.380879\tvalid_1's l2: 0.471043\n",
      "[3500]\ttraining's l2: 0.370096\tvalid_1's l2: 0.469745\n",
      "[4000]\ttraining's l2: 0.360304\tvalid_1's l2: 0.469067\n",
      "[4500]\ttraining's l2: 0.351286\tvalid_1's l2: 0.468523\n",
      "[5000]\ttraining's l2: 0.342893\tvalid_1's l2: 0.468387\n",
      "[5500]\ttraining's l2: 0.334899\tvalid_1's l2: 0.468037\n",
      "[6000]\ttraining's l2: 0.327366\tvalid_1's l2: 0.468065\n",
      "[6500]\ttraining's l2: 0.320218\tvalid_1's l2: 0.467797\n",
      "[7000]\ttraining's l2: 0.313401\tvalid_1's l2: 0.468027\n",
      "Early stopping, best iteration is:\n",
      "[6478]\ttraining's l2: 0.32053\tvalid_1's l2: 0.467766\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.504079\tvalid_1's l2: 0.515304\n",
      "[1000]\ttraining's l2: 0.45461\tvalid_1's l2: 0.482222\n",
      "[1500]\ttraining's l2: 0.428277\tvalid_1's l2: 0.469229\n",
      "[2000]\ttraining's l2: 0.410317\tvalid_1's l2: 0.462316\n",
      "[2500]\ttraining's l2: 0.396404\tvalid_1's l2: 0.458244\n",
      "[3000]\ttraining's l2: 0.384382\tvalid_1's l2: 0.455325\n",
      "[3500]\ttraining's l2: 0.373786\tvalid_1's l2: 0.453551\n",
      "[4000]\ttraining's l2: 0.364184\tvalid_1's l2: 0.451763\n",
      "[4500]\ttraining's l2: 0.355203\tvalid_1's l2: 0.450724\n",
      "[5000]\ttraining's l2: 0.346848\tvalid_1's l2: 0.449857\n",
      "[5500]\ttraining's l2: 0.33895\tvalid_1's l2: 0.449188\n",
      "[6000]\ttraining's l2: 0.331333\tvalid_1's l2: 0.448811\n",
      "[6500]\ttraining's l2: 0.324086\tvalid_1's l2: 0.448652\n",
      "[7000]\ttraining's l2: 0.3172\tvalid_1's l2: 0.448685\n",
      "[7500]\ttraining's l2: 0.310548\tvalid_1's l2: 0.448159\n",
      "[8000]\ttraining's l2: 0.304225\tvalid_1's l2: 0.447825\n",
      "[8500]\ttraining's l2: 0.298135\tvalid_1's l2: 0.447573\n",
      "[9000]\ttraining's l2: 0.292181\tvalid_1's l2: 0.447249\n",
      "[9500]\ttraining's l2: 0.286486\tvalid_1's l2: 0.447188\n",
      "[10000]\ttraining's l2: 0.280931\tvalid_1's l2: 0.447018\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l2: 0.280931\tvalid_1's l2: 0.447018\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.503886\tvalid_1's l2: 0.51828\n",
      "[1000]\ttraining's l2: 0.455732\tvalid_1's l2: 0.480204\n",
      "[1500]\ttraining's l2: 0.43017\tvalid_1's l2: 0.463689\n",
      "[2000]\ttraining's l2: 0.412494\tvalid_1's l2: 0.454749\n",
      "[2500]\ttraining's l2: 0.398303\tvalid_1's l2: 0.449137\n",
      "[3000]\ttraining's l2: 0.386406\tvalid_1's l2: 0.445904\n",
      "[3500]\ttraining's l2: 0.375601\tvalid_1's l2: 0.443768\n",
      "[4000]\ttraining's l2: 0.365819\tvalid_1's l2: 0.44215\n",
      "[4500]\ttraining's l2: 0.356886\tvalid_1's l2: 0.441105\n",
      "[5000]\ttraining's l2: 0.348432\tvalid_1's l2: 0.440186\n",
      "[5500]\ttraining's l2: 0.340314\tvalid_1's l2: 0.439193\n",
      "[6000]\ttraining's l2: 0.332728\tvalid_1's l2: 0.438617\n",
      "[6500]\ttraining's l2: 0.325412\tvalid_1's l2: 0.438355\n",
      "[7000]\ttraining's l2: 0.318532\tvalid_1's l2: 0.438221\n",
      "Early stopping, best iteration is:\n",
      "[6679]\ttraining's l2: 0.322911\tvalid_1's l2: 0.43815\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.504825\tvalid_1's l2: 0.513947\n",
      "[1000]\ttraining's l2: 0.45576\tvalid_1's l2: 0.478685\n",
      "[1500]\ttraining's l2: 0.429098\tvalid_1's l2: 0.46619\n",
      "[2000]\ttraining's l2: 0.410943\tvalid_1's l2: 0.46006\n",
      "[2500]\ttraining's l2: 0.3966\tvalid_1's l2: 0.456692\n",
      "[3000]\ttraining's l2: 0.38446\tvalid_1's l2: 0.454425\n",
      "[3500]\ttraining's l2: 0.373834\tvalid_1's l2: 0.453328\n",
      "[4000]\ttraining's l2: 0.364121\tvalid_1's l2: 0.452405\n",
      "[4500]\ttraining's l2: 0.355039\tvalid_1's l2: 0.45132\n",
      "[5000]\ttraining's l2: 0.346571\tvalid_1's l2: 0.450552\n",
      "[5500]\ttraining's l2: 0.338705\tvalid_1's l2: 0.449867\n",
      "[6000]\ttraining's l2: 0.331035\tvalid_1's l2: 0.449277\n",
      "[6500]\ttraining's l2: 0.323816\tvalid_1's l2: 0.449272\n",
      "[7000]\ttraining's l2: 0.316929\tvalid_1's l2: 0.449195\n",
      "[7500]\ttraining's l2: 0.310277\tvalid_1's l2: 0.448961\n",
      "[8000]\ttraining's l2: 0.303788\tvalid_1's l2: 0.449011\n",
      "[8500]\ttraining's l2: 0.297721\tvalid_1's l2: 0.448984\n",
      "[9000]\ttraining's l2: 0.291734\tvalid_1's l2: 0.448962\n",
      "[9500]\ttraining's l2: 0.285825\tvalid_1's l2: 0.44897\n",
      "Early stopping, best iteration is:\n",
      "[9075]\ttraining's l2: 0.290877\tvalid_1's l2: 0.448777\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.503496\tvalid_1's l2: 0.520801\n",
      "[1000]\ttraining's l2: 0.45511\tvalid_1's l2: 0.485264\n",
      "[1500]\ttraining's l2: 0.428964\tvalid_1's l2: 0.470873\n",
      "[2000]\ttraining's l2: 0.410878\tvalid_1's l2: 0.464105\n",
      "[2500]\ttraining's l2: 0.396314\tvalid_1's l2: 0.460144\n",
      "[3000]\ttraining's l2: 0.383975\tvalid_1's l2: 0.45793\n",
      "[3500]\ttraining's l2: 0.372925\tvalid_1's l2: 0.456429\n",
      "[4000]\ttraining's l2: 0.363012\tvalid_1's l2: 0.455681\n",
      "[4500]\ttraining's l2: 0.353856\tvalid_1's l2: 0.455703\n",
      "Early stopping, best iteration is:\n",
      "[4188]\ttraining's l2: 0.359496\tvalid_1's l2: 0.4555\n",
      "CV score: 0.45144215\n"
     ]
    }
   ],
   "source": [
    "lgb_263_param = {\n",
    "'num_leaves': 7, \n",
    "'min_data_in_leaf': 20,\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.003,\n",
    "\"boosting\": \"gbdt\", \n",
    "\"feature_fraction\": 0.18, \n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.55, \n",
    "\"bagging_seed\": 14,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l1\": 0.1,\n",
    "\"lambda_l2\": 0.2, \n",
    "\"verbosity\": -1}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)   \n",
    "oof_lgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_lgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_263[val_idx], y_train[val_idx])#train:val=4:1\n",
    "\n",
    "    num_round = 10000\n",
    "    lgb_263 = lgb.train(lgb_263_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 800)\n",
    "    oof_lgb_263[val_idx] = lgb_263.predict(X_train_263[val_idx], num_iteration=lgb_263.best_iteration)\n",
    "    predictions_lgb_263 += lgb_263.predict(X_test_263, num_iteration=lgb_263.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x2016 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "pd.set_option('max_colwidth',100)\n",
    "df = pd.DataFrame(data[use_feature].columns.tolist(), columns=['feature'])\n",
    "df['importance']=list(lgb_263.feature_importance())\n",
    "df = df.sort_values(by='importance',ascending=False)\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df.head(50))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[22:20:59] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:20:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39995\tvalid_data-rmse:3.40008\n",
      "[500]\ttrain-rmse:0.40782\tvalid_data-rmse:0.68277\n",
      "[1000]\ttrain-rmse:0.27559\tvalid_data-rmse:0.68439\n",
      "[1125]\ttrain-rmse:0.24886\tvalid_data-rmse:0.68444\n",
      "fold n°2\n",
      "[22:22:32] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:22:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40000\tvalid_data-rmse:3.40006\n",
      "[500]\ttrain-rmse:0.40983\tvalid_data-rmse:0.67543\n",
      "[1000]\ttrain-rmse:0.27350\tvalid_data-rmse:0.67560\n",
      "[1440]\ttrain-rmse:0.19328\tvalid_data-rmse:0.67824\n",
      "fold n°3\n",
      "[22:24:37] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:24:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39997\tvalid_data-rmse:3.40036\n",
      "[500]\ttrain-rmse:0.41300\tvalid_data-rmse:0.67145\n",
      "[1000]\ttrain-rmse:0.27423\tvalid_data-rmse:0.67193\n",
      "[1324]\ttrain-rmse:0.21139\tvalid_data-rmse:0.67338\n",
      "fold n°4\n",
      "[22:26:04] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:26:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40009\tvalid_data-rmse:3.40056\n",
      "[500]\ttrain-rmse:0.40786\tvalid_data-rmse:0.67191\n",
      "[1000]\ttrain-rmse:0.27369\tvalid_data-rmse:0.67119\n",
      "[1267]\ttrain-rmse:0.22153\tvalid_data-rmse:0.67096\n",
      "fold n°5\n",
      "[22:27:44] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:27:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40025\tvalid_data-rmse:3.40007\n",
      "[500]\ttrain-rmse:0.41059\tvalid_data-rmse:0.66269\n",
      "[1000]\ttrain-rmse:0.27544\tvalid_data-rmse:0.66467\n",
      "[1146]\ttrain-rmse:0.24466\tvalid_data-rmse:0.66483\n",
      "CV score: 0.45174660\n"
     ]
    }
   ],
   "source": [
    "xgb_263_params = {'eta': 0.02,  \n",
    "              'max_depth': 6,  \n",
    "              'min_child_weight':3,\n",
    "              'gamma':0,\n",
    "              'subsample': 0.7,  \n",
    "              'colsample_bytree': 0.3, \n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_xgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_263[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_263 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_263_params)\n",
    "    oof_xgb_263[val_idx] = xgb_263.predict(xgb.DMatrix(X_train_263[val_idx]), ntree_limit=xgb_263.best_ntree_limit)\n",
    "    predictions_xgb_263 += xgb_263.predict(xgb.DMatrix(X_test_263), ntree_limit=xgb_263.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.47764934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_rfr_263 = np.zeros(len(X_train_263))\n",
    "predictions_rfr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    rfr_263 = rfr(n_estimators=1600,max_depth=9, min_samples_leaf=9, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.25,verbose=1,n_jobs=-1) \n",
    "    #verbose = 0 \n",
    "#verbose = 1 \n",
    "#verbose = 2 \n",
    "    rfr_263.fit(tr_x,tr_y)\n",
    "    oof_rfr_263[val_idx] = rfr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_rfr_263 += rfr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_rfr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6848           0.0034           36.33s\n",
      "         2           0.6498           0.0035           36.02s\n",
      "         3           0.6574           0.0030           42.17s\n",
      "         4           0.6366           0.0033           39.40s\n",
      "         5           0.6420           0.0035           35.97s\n",
      "         6           0.6390           0.0028           33.81s\n",
      "         7           0.6263           0.0031           34.67s\n",
      "         8           0.6283           0.0031           36.34s\n",
      "         9           0.6315           0.0027           41.58s\n",
      "        10           0.6197           0.0028           40.13s\n",
      "        20           0.6057           0.0020           32.33s\n",
      "        30           0.5571           0.0018           28.96s\n",
      "        40           0.5505           0.0015           28.70s\n",
      "        50           0.5139           0.0012           27.05s\n",
      "        60           0.4879           0.0012           25.65s\n",
      "        70           0.4741           0.0011           26.48s\n",
      "        80           0.4547           0.0009           25.97s\n",
      "        90           0.4322           0.0005           25.50s\n",
      "       100           0.4209           0.0006           25.80s\n",
      "       200           0.3520           0.0000           18.06s\n",
      "       300           0.2968          -0.0000            8.34s\n",
      "       400           0.2698          -0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6924           0.0034           41.37s\n",
      "         2           0.6801           0.0031           36.64s\n",
      "         3           0.6696           0.0032           40.25s\n",
      "         4           0.6570           0.0032           37.46s\n",
      "         5           0.6520           0.0031           39.31s\n",
      "         6           0.6433           0.0030           45.91s\n",
      "         7           0.6675           0.0030           43.02s\n",
      "         8           0.6305           0.0029           44.71s\n",
      "         9           0.6433           0.0030           42.52s\n",
      "        10           0.6323           0.0032           40.74s\n",
      "        20           0.5917           0.0027           34.87s\n",
      "        30           0.5550           0.0020           31.53s\n",
      "        40           0.5223           0.0015           29.66s\n",
      "        50           0.5081           0.0015           27.83s\n",
      "        60           0.4831           0.0012           26.16s\n",
      "        70           0.4908           0.0009           25.05s\n",
      "        80           0.4639           0.0008           24.27s\n",
      "        90           0.4437           0.0007           23.12s\n",
      "       100           0.4216           0.0006           25.73s\n",
      "       200           0.3412           0.0001           18.44s\n",
      "       300           0.2925           0.0000            8.34s\n",
      "       400           0.2736           0.0001            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6827           0.0031           36.81s\n",
      "         2           0.6593           0.0034           29.94s\n",
      "         3           0.6530           0.0032           32.25s\n",
      "         4           0.6415           0.0031           31.34s\n",
      "         5           0.6633           0.0031           29.70s\n",
      "         6           0.6629           0.0030           33.14s\n",
      "         7           0.6348           0.0031           33.26s\n",
      "         8           0.6480           0.0028           32.10s\n",
      "         9           0.6128           0.0030           33.73s\n",
      "        10           0.6231           0.0027           35.93s\n",
      "        20           0.5985           0.0022           32.53s\n",
      "        30           0.5653           0.0020           29.66s\n",
      "        40           0.5243           0.0016           29.27s\n",
      "        50           0.5014           0.0013           27.48s\n",
      "        60           0.4877           0.0013           26.26s\n",
      "        70           0.4751           0.0009           25.77s\n",
      "        80           0.4363           0.0008           24.56s\n",
      "        90           0.4412           0.0007           23.64s\n",
      "       100           0.4232           0.0006           22.99s\n",
      "       200           0.3425           0.0002           14.36s\n",
      "       300           0.2962           0.0000            6.99s\n",
      "       400           0.2589          -0.0000            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6611           0.0034           45.86s\n",
      "         2           0.6686           0.0033           35.91s\n",
      "         3           0.6468           0.0032           40.01s\n",
      "         4           0.6492           0.0032           36.65s\n",
      "         5           0.6450           0.0033           33.71s\n",
      "         6           0.6569           0.0031           31.79s\n",
      "         7           0.6595           0.0030           34.12s\n",
      "         8           0.6591           0.0026           32.90s\n",
      "         9           0.6458           0.0029           31.70s\n",
      "        10           0.6235           0.0028           30.71s\n",
      "        20           0.5885           0.0021           31.62s\n",
      "        30           0.5551           0.0020           29.58s\n",
      "        40           0.5332           0.0018           27.36s\n",
      "        50           0.5116           0.0013           26.97s\n",
      "        60           0.4863           0.0012           25.57s\n",
      "        70           0.4730           0.0009           24.53s\n",
      "        80           0.4587           0.0008           24.22s\n",
      "        90           0.4298           0.0010           25.45s\n",
      "       100           0.4244           0.0003           24.94s\n",
      "       200           0.3477           0.0002           17.44s\n",
      "       300           0.3000          -0.0000            8.04s\n",
      "       400           0.2566           0.0000            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6663           0.0035           42.59s\n",
      "         2           0.6786           0.0029           39.50s\n",
      "         3           0.6435           0.0036           35.16s\n",
      "         4           0.6649           0.0032           34.00s\n",
      "         5           0.6365           0.0030           35.71s\n",
      "         6           0.6588           0.0029           33.45s\n",
      "         7           0.6621           0.0031           31.76s\n",
      "         8           0.6579           0.0024           34.54s\n",
      "         9           0.6025           0.0030           33.64s\n",
      "        10           0.6500           0.0029           32.45s\n",
      "        20           0.5846           0.0026           31.42s\n",
      "        30           0.5577           0.0020           29.94s\n",
      "        40           0.5290           0.0014           27.49s\n",
      "        50           0.5063           0.0015           25.77s\n",
      "        60           0.4885           0.0013           25.21s\n",
      "        70           0.4689           0.0011           24.29s\n",
      "        80           0.4539           0.0007           23.61s\n",
      "        90           0.4334           0.0006           22.81s\n",
      "       100           0.4241           0.0006           21.83s\n",
      "       200           0.3471           0.0001           13.86s\n",
      "       300           0.2950           0.0001            6.82s\n",
      "       400           0.2624           0.0000            0.00s\n",
      "CV score: 0.45636155\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_263 = np.zeros(train_shape)\n",
    "predictions_gbr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_263 = gbr(n_estimators=400, learning_rate=0.01,subsample=0.65,max_depth=7, min_samples_leaf=20,\n",
    "            max_features=0.22,verbose=1)\n",
    "    gbr_263.fit(tr_x,tr_y)\n",
    "    oof_gbr_263[val_idx] = gbr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_gbr_263 += gbr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   40.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   37.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   36.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   45.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   45.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.48511053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_etr_263 = np.zeros(train_shape)\n",
    "predictions_etr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    etr_263 = etr(n_estimators=1000,max_depth=8, min_samples_leaf=12, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.4,verbose=1,n_jobs=-1)\n",
    "    etr_263.fit(tr_x,tr_y)\n",
    "    oof_etr_263[val_idx] = etr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_etr_263 += etr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_etr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling & Feature Engineering - 49 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.470708\tvalid_1's l2: 0.49533\n",
      "[2000]\ttraining's l2: 0.430792\tvalid_1's l2: 0.475723\n",
      "[3000]\ttraining's l2: 0.408352\tvalid_1's l2: 0.470283\n",
      "[4000]\ttraining's l2: 0.390566\tvalid_1's l2: 0.467745\n",
      "[5000]\ttraining's l2: 0.375195\tvalid_1's l2: 0.466929\n",
      "[6000]\ttraining's l2: 0.36138\tvalid_1's l2: 0.466331\n",
      "[7000]\ttraining's l2: 0.348785\tvalid_1's l2: 0.466362\n",
      "Early stopping, best iteration is:\n",
      "[6501]\ttraining's l2: 0.354929\tvalid_1's l2: 0.466144\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.470545\tvalid_1's l2: 0.494825\n",
      "[2000]\ttraining's l2: 0.429727\tvalid_1's l2: 0.475862\n",
      "[3000]\ttraining's l2: 0.40708\tvalid_1's l2: 0.471551\n",
      "[4000]\ttraining's l2: 0.389121\tvalid_1's l2: 0.469654\n",
      "[5000]\ttraining's l2: 0.373686\tvalid_1's l2: 0.46918\n",
      "[6000]\ttraining's l2: 0.359722\tvalid_1's l2: 0.468886\n",
      "[7000]\ttraining's l2: 0.346965\tvalid_1's l2: 0.469111\n",
      "Early stopping, best iteration is:\n",
      "[6270]\ttraining's l2: 0.356212\tvalid_1's l2: 0.46873\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.473817\tvalid_1's l2: 0.486868\n",
      "[2000]\ttraining's l2: 0.432916\tvalid_1's l2: 0.463987\n",
      "[3000]\ttraining's l2: 0.409862\tvalid_1's l2: 0.45977\n",
      "[4000]\ttraining's l2: 0.391963\tvalid_1's l2: 0.459267\n",
      "Early stopping, best iteration is:\n",
      "[3581]\ttraining's l2: 0.398964\tvalid_1's l2: 0.459067\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.467453\tvalid_1's l2: 0.506157\n",
      "[2000]\ttraining's l2: 0.427734\tvalid_1's l2: 0.487989\n",
      "[3000]\ttraining's l2: 0.405938\tvalid_1's l2: 0.482703\n",
      "[4000]\ttraining's l2: 0.388516\tvalid_1's l2: 0.479893\n",
      "[5000]\ttraining's l2: 0.373592\tvalid_1's l2: 0.477979\n",
      "[6000]\ttraining's l2: 0.360348\tvalid_1's l2: 0.476099\n",
      "[7000]\ttraining's l2: 0.348106\tvalid_1's l2: 0.474507\n",
      "[8000]\ttraining's l2: 0.336668\tvalid_1's l2: 0.473431\n",
      "[9000]\ttraining's l2: 0.325903\tvalid_1's l2: 0.472694\n",
      "[10000]\ttraining's l2: 0.315893\tvalid_1's l2: 0.471945\n",
      "[11000]\ttraining's l2: 0.306348\tvalid_1's l2: 0.471507\n",
      "[12000]\ttraining's l2: 0.297339\tvalid_1's l2: 0.47098\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[12000]\ttraining's l2: 0.297339\tvalid_1's l2: 0.47098\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.46928\tvalid_1's l2: 0.501034\n",
      "[2000]\ttraining's l2: 0.428616\tvalid_1's l2: 0.483187\n",
      "[3000]\ttraining's l2: 0.40604\tvalid_1's l2: 0.478915\n",
      "[4000]\ttraining's l2: 0.387937\tvalid_1's l2: 0.477565\n",
      "[5000]\ttraining's l2: 0.372545\tvalid_1's l2: 0.476637\n",
      "[6000]\ttraining's l2: 0.358689\tvalid_1's l2: 0.476453\n",
      "Early stopping, best iteration is:\n",
      "[5943]\ttraining's l2: 0.359451\tvalid_1's l2: 0.476381\n",
      "CV score: 0.46825906\n"
     ]
    }
   ],
   "source": [
    "lgb_49_param = {\n",
    "'num_leaves': 9,\n",
    "'min_data_in_leaf': 23,\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.002,\n",
    "\"boosting\": \"gbdt\",\n",
    "\"feature_fraction\": 0.45, \n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.65, \n",
    "\"bagging_seed\": 15,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l2\": 0.2, \n",
    "\"verbosity\": -1} \n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)   \n",
    "oof_lgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_lgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 12000\n",
    "    lgb_49 = lgb.train(lgb_49_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n",
    "    oof_lgb_49[val_idx] = lgb_49.predict(X_train_49[val_idx], num_iteration=lgb_49.best_iteration)\n",
    "    predictions_lgb_49 += lgb_49.predict(X_test_49, num_iteration=lgb_49.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[00:50:53] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:50:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40427\tvalid_data-rmse:3.38313\n",
      "[500]\ttrain-rmse:0.52689\tvalid_data-rmse:0.72122\n",
      "[1000]\ttrain-rmse:0.43485\tvalid_data-rmse:0.72264\n",
      "[1163]\ttrain-rmse:0.40941\tvalid_data-rmse:0.72325\n",
      "fold n°2\n",
      "[00:51:06] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39815\tvalid_data-rmse:3.40775\n",
      "[500]\ttrain-rmse:0.52873\tvalid_data-rmse:0.70251\n",
      "[1000]\ttrain-rmse:0.43864\tvalid_data-rmse:0.70453\n",
      "[1129]\ttrain-rmse:0.41923\tvalid_data-rmse:0.70522\n",
      "fold n°3\n",
      "[00:51:18] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40182\tvalid_data-rmse:3.39292\n",
      "[500]\ttrain-rmse:0.53359\tvalid_data-rmse:0.66857\n",
      "[1000]\ttrain-rmse:0.44062\tvalid_data-rmse:0.67166\n",
      "[1027]\ttrain-rmse:0.43640\tvalid_data-rmse:0.67226\n",
      "fold n°4\n",
      "[00:51:29] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40241\tvalid_data-rmse:3.39010\n",
      "[500]\ttrain-rmse:0.53255\tvalid_data-rmse:0.67770\n",
      "[1000]\ttrain-rmse:0.44371\tvalid_data-rmse:0.68044\n",
      "[1098]\ttrain-rmse:0.42784\tvalid_data-rmse:0.68151\n",
      "fold n°5\n",
      "[00:51:43] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39345\tvalid_data-rmse:3.42630\n",
      "[500]\ttrain-rmse:0.53439\tvalid_data-rmse:0.66117\n",
      "[1000]\ttrain-rmse:0.44084\tvalid_data-rmse:0.66248\n",
      "[1344]\ttrain-rmse:0.39053\tvalid_data-rmse:0.66426\n",
      "CV score: 0.47091244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_49_params = {'eta': 0.02, \n",
    "              'max_depth': 5, \n",
    "              'min_child_weight':3,\n",
    "              'gamma':0,\n",
    "              'subsample': 0.7, \n",
    "              'colsample_bytree': 0.35, \n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_xgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_49 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_49_params)\n",
    "    oof_xgb_49[val_idx] = xgb_49.predict(xgb.DMatrix(X_train_49[val_idx]), ntree_limit=xgb_49.best_ntree_limit)\n",
    "    predictions_xgb_49 += xgb_49.predict(xgb.DMatrix(X_test_49), ntree_limit=xgb_49.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6589           0.0033           18.70s\n",
      "         2           0.6727           0.0033           18.76s\n",
      "         3           0.6633           0.0031           20.59s\n",
      "         4           0.6521           0.0031           20.65s\n",
      "         5           0.6546           0.0029           19.42s\n",
      "         6           0.6338           0.0032           18.58s\n",
      "         7           0.6464           0.0028           19.06s\n",
      "         8           0.6280           0.0030           20.19s\n",
      "         9           0.6492           0.0029           20.58s\n",
      "        10           0.6203           0.0029           19.85s\n",
      "        20           0.5951           0.0024           17.50s\n",
      "        30           0.5657           0.0022           22.89s\n",
      "        40           0.5556           0.0016           21.81s\n",
      "        50           0.5416           0.0012           20.54s\n",
      "        60           0.5237           0.0011           20.40s\n",
      "        70           0.4948           0.0009           19.50s\n",
      "        80           0.4865           0.0005           18.38s\n",
      "        90           0.4677           0.0006           18.27s\n",
      "       100           0.4608           0.0005           17.54s\n",
      "       200           0.3913           0.0001           13.70s\n",
      "       300           0.3709          -0.0000            9.65s\n",
      "       400           0.3419          -0.0000            6.24s\n",
      "       500           0.3246          -0.0000            3.01s\n",
      "       600           0.3323          -0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6701           0.0032           16.88s\n",
      "         2           0.6552           0.0033           17.61s\n",
      "         3           0.6738           0.0028           17.57s\n",
      "         4           0.6577           0.0030           18.24s\n",
      "         5           0.6398           0.0031           18.70s\n",
      "         6           0.6555           0.0028           18.98s\n",
      "         7           0.6396           0.0031           18.57s\n",
      "         8           0.6354           0.0032           18.08s\n",
      "         9           0.6581           0.0028           17.92s\n",
      "        10           0.6362           0.0029           17.78s\n",
      "        20           0.6048           0.0022           18.08s\n",
      "        30           0.5654           0.0021           17.46s\n",
      "        40           0.5529           0.0015           16.82s\n",
      "        50           0.5281           0.0012           17.34s\n",
      "        60           0.4896           0.0010           16.40s\n",
      "        70           0.4843           0.0010           16.46s\n",
      "        80           0.4676           0.0008           15.89s\n",
      "        90           0.4749           0.0006           15.39s\n",
      "       100           0.4688           0.0005           14.81s\n",
      "       200           0.3915           0.0000           11.52s\n",
      "       300           0.3738           0.0000            8.82s\n",
      "       400           0.3492          -0.0001            6.06s\n",
      "       500           0.3256          -0.0001            3.00s\n",
      "       600           0.3081          -0.0000            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6694           0.0030           14.11s\n",
      "         2           0.6523           0.0035           14.40s\n",
      "         3           0.6574           0.0032           14.25s\n",
      "         4           0.6706           0.0030           15.45s\n",
      "         5           0.6519           0.0032           17.84s\n",
      "         6           0.6554           0.0032           18.45s\n",
      "         7           0.6571           0.0030           19.14s\n",
      "         8           0.6281           0.0030           20.60s\n",
      "         9           0.6347           0.0027           20.35s\n",
      "        10           0.6221           0.0030           20.08s\n",
      "        20           0.5997           0.0024           19.91s\n",
      "        30           0.5695           0.0020           17.70s\n",
      "        40           0.5356           0.0015           17.22s\n",
      "        50           0.5305           0.0014           16.93s\n",
      "        60           0.5022           0.0012           16.33s\n",
      "        70           0.4981           0.0009           15.87s\n",
      "        80           0.4857           0.0008           15.32s\n",
      "        90           0.4580           0.0005           15.05s\n",
      "       100           0.4568           0.0006           14.50s\n",
      "       200           0.3946           0.0001           11.60s\n",
      "       300           0.3570           0.0000            8.65s\n",
      "       400           0.3372          -0.0000            5.54s\n",
      "       500           0.3207          -0.0001            2.76s\n",
      "       600           0.3065           0.0000            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6722           0.0034           14.71s\n",
      "         2           0.6649           0.0034           14.95s\n",
      "         3           0.6788           0.0032           14.75s\n",
      "         4           0.6659           0.0032           15.54s\n",
      "         5           0.6433           0.0031           16.91s\n",
      "         6           0.6406           0.0029           18.90s\n",
      "         7           0.6502           0.0026           20.00s\n",
      "         8           0.6319           0.0028           20.25s\n",
      "         9           0.6453           0.0028           21.25s\n",
      "        10           0.6275           0.0029           21.71s\n",
      "        20           0.6084           0.0025           20.03s\n",
      "        30           0.5551           0.0020           19.93s\n",
      "        40           0.5491           0.0016           18.90s\n",
      "        50           0.5200           0.0013           18.41s\n",
      "        60           0.5082           0.0012           17.62s\n",
      "        70           0.4948           0.0009           18.18s\n",
      "        80           0.4833           0.0007           18.64s\n",
      "        90           0.4748           0.0008           18.68s\n",
      "       100           0.4593           0.0006           18.81s\n",
      "       200           0.3922           0.0001           13.64s\n",
      "       300           0.3691           0.0000            9.59s\n",
      "       400           0.3507          -0.0000            6.21s\n",
      "       500           0.3281           0.0000            3.10s\n",
      "       600           0.3156          -0.0001            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6608           0.0034           23.75s\n",
      "         2           0.6551           0.0034           22.30s\n",
      "         3           0.6666           0.0030           23.97s\n",
      "         4           0.6426           0.0030           23.45s\n",
      "         5           0.6658           0.0034           23.91s\n",
      "         6           0.6429           0.0031           23.68s\n",
      "         7           0.6211           0.0028           22.51s\n",
      "         8           0.6590           0.0029           22.63s\n",
      "         9           0.6375           0.0028           24.02s\n",
      "        10           0.6240           0.0028           24.35s\n",
      "        20           0.6062           0.0022           21.61s\n",
      "        30           0.5614           0.0018           20.68s\n",
      "        40           0.5606           0.0014           19.77s\n",
      "        50           0.5278           0.0013           19.73s\n",
      "        60           0.5207           0.0011           18.79s\n",
      "        70           0.5051           0.0008           17.93s\n",
      "        80           0.4879           0.0009           17.46s\n",
      "        90           0.4753           0.0005           16.74s\n",
      "       100           0.4661           0.0006           16.21s\n",
      "       200           0.3934           0.0001           11.91s\n",
      "       300           0.3681          -0.0000            9.07s\n",
      "       400           0.3370          -0.0001            5.90s\n",
      "       500           0.3261          -0.0000            2.99s\n",
      "       600           0.3033          -0.0000            0.00s\n",
      "CV score: 0.47075211\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_49 = np.zeros(train_shape)\n",
    "predictions_gbr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_49 = gbr(n_estimators=600, learning_rate=0.01,subsample=0.65,max_depth=6, min_samples_leaf=20,\n",
    "            max_features=0.35,verbose=1)\n",
    "    gbr_49.fit(tr_x,tr_y)\n",
    "    oof_gbr_49[val_idx] = gbr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_gbr_49 += gbr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4670808903788372"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack3 = np.vstack([oof_lgb_49,oof_xgb_49,oof_gbr_49]).transpose()\n",
    "test_stack3 = np.vstack([predictions_lgb_49, predictions_xgb_49,predictions_gbr_49]).transpose()\n",
    "#\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack3 = np.zeros(train_stack3.shape[0])\n",
    "predictions_lr3 = np.zeros(test_stack3.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack3,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack3[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack3[val_idx], target.iloc[val_idx].values\n",
    "        #Kernel Ridge Regression\n",
    "    lr3 = kr()\n",
    "    lr3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack3[val_idx] = lr3.predict(val_data)\n",
    "    predictions_lr3 += lr3.predict(test_stack3) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_49 = np.zeros(train_shape)\n",
    "predictions_kr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    kr_49 = kr()\n",
    "    kr_49.fit(tr_x,tr_y)\n",
    "    oof_kr_49[val_idx] = kr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_kr_49 += kr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_49 = np.zeros(train_shape)\n",
    "predictions_ridge_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    ridge_49 = Ridge(alpha=6)\n",
    "    ridge_49.fit(tr_x,tr_y)\n",
    "    oof_ridge_49[val_idx] = ridge_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_ridge_49 += ridge_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_49 = np.zeros(train_shape)\n",
    "predictions_br_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    br_49 = br()\n",
    "    br_49.fit(tr_x,tr_y)\n",
    "    oof_br_49[val_idx] = br_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_br_49 += br_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_49 = np.zeros(train_shape)\n",
    "predictions_en_49 = np.zeros(len(X_test_49))\n",
    "#\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    en_49 = en(alpha=1.0,l1_ratio=0.05)\n",
    "    en_49.fit(tr_x,tr_y)\n",
    "    oof_en_49[val_idx] = en_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_en_49 += en_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack4 = np.vstack([oof_br_49,oof_kr_49,oof_en_49,oof_ridge_49]).transpose()\n",
    "test_stack4 = np.vstack([predictions_br_49, predictions_kr_49,predictions_en_49,predictions_ridge_49]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack4 = np.zeros(train_stack4.shape[0])\n",
    "predictions_lr4 = np.zeros(test_stack4.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack4,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack4[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack4[val_idx], target.iloc[val_idx].values\n",
    "    #LinearRegression\n",
    "    lr4 = lr()\n",
    "    lr4.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack4[val_idx] = lr4.predict(val_data)\n",
    "    predictions_lr4 += lr4.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack4) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Feature Engineering - 383 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_383 = np.zeros(train_shape)\n",
    "predictions_kr_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    kr_383 = kr()\n",
    "    kr_383.fit(tr_x,tr_y)\n",
    "    oof_kr_383[val_idx] = kr_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_kr_383 += kr_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_383 = np.zeros(train_shape)\n",
    "predictions_ridge_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    ridge_383 = Ridge(alpha=1200)\n",
    "    ridge_383.fit(tr_x,tr_y)\n",
    "    oof_ridge_383[val_idx] = ridge_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_ridge_383 += ridge_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_383 = np.zeros(train_shape)\n",
    "predictions_en_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    en_383 = en(alpha=1.0,l1_ratio=0.06)\n",
    "    en_383.fit(tr_x,tr_y)\n",
    "    oof_en_383[val_idx] = en_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_en_383 += en_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesianRidge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_383 = np.zeros(train_shape)\n",
    "predictions_br_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    br_383 = br()\n",
    "    br_383.fit(tr_x,tr_y)\n",
    "    oof_br_383[val_idx] = br_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_br_383 += br_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack1 = np.vstack([oof_br_383,oof_kr_383,oof_en_383,oof_ridge_383]).transpose()\n",
    "test_stack1 = np.vstack([predictions_br_383, predictions_kr_383,predictions_en_383,predictions_ridge_383]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack1 = np.zeros(train_stack1.shape[0])\n",
    "predictions_lr1 = np.zeros(test_stack1.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack1,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack1[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack1[val_idx], target.iloc[val_idx].values\n",
    "    # LinearRegression简单的线性回归\n",
    "    lr1 = lr()\n",
    "    lr1.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack1[val_idx] = lr1.predict(val_data)\n",
    "    predictions_lr1 += lr1.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
