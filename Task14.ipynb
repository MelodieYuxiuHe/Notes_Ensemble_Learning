{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of 'Happiness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error,mean_absolute_error, f1_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "from sklearn.linear_model import BayesianRidge as br\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.linear_model import ElasticNet as en\n",
    "from sklearn.kernel_ridge import KernelRidge as kr\n",
    "from sklearn.model_selection import  KFold, StratifiedKFold,GroupKFold, RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/Melodie/Downloads/2021Spring/Study/DataWhale/April_Ensembled_Learning/Notes_Ensemble_Learning/Data/case_1/train.csv\", parse_dates=['survey_time'],encoding='latin-1') \n",
    "test = pd.read_csv(\"/Users/Melodie/Downloads/2021Spring/Study/DataWhale/April_Ensembled_Learning/Notes_Ensemble_Learning/Data/case_1/test.csv\", parse_dates=['survey_time'],encoding='latin-1') #latin-1向下兼容ASCII\n",
    "\n",
    "#Remove the 'happiness' variable\n",
    "train = train[train[\"happiness\"]!=-8].reset_index(drop=True)\n",
    "train_data_copy = train.copy() \n",
    "\n",
    "#'Happiness' variable\n",
    "target_col = \"happiness\" \n",
    "target = train_data_copy[target_col]\n",
    "del train_data_copy[target_col] \n",
    "\n",
    "data = pd.concat([train_data_copy,test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA 'Happiness' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7988.000000\n",
       "mean        3.867927\n",
       "std         0.818717\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         4.000000\n",
       "75%         4.000000\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.happiness.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'survey_type', 'province', 'city', 'county', 'survey_time',\n",
       "       'gender', 'birth', 'nationality', 'religion',\n",
       "       ...\n",
       "       'neighbor_familiarity', 'public_service_1', 'public_service_2',\n",
       "       'public_service_3', 'public_service_4', 'public_service_5',\n",
       "       'public_service_6', 'public_service_7', 'public_service_8',\n",
       "       'public_service_9'],\n",
       "      dtype='object', length=139)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some negative values. We wants to figure out how many such negative values in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getres1(row):\n",
    "    return len([x for x in row.values if type(x)==int and x<0])\n",
    "\n",
    "def getres2(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-8])\n",
    "\n",
    "def getres3(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-1])\n",
    "\n",
    "def getres4(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-2])\n",
    "\n",
    "def getres5(row):\n",
    "    return len([x for x in row.values if type(x)==int and x==-3])\n",
    "\n",
    "data['neg1'] = data[data.columns].apply(lambda row:getres1(row),axis=1)\n",
    "data['neg2'] = data[data.columns].apply(lambda row:getres2(row),axis=1)\n",
    "data['neg3'] = data[data.columns].apply(lambda row:getres3(row),axis=1)\n",
    "data['neg4'] = data[data.columns].apply(lambda row:getres4(row),axis=1)\n",
    "data['neg5'] = data[data.columns].apply(lambda row:getres5(row),axis=1)\n",
    "\n",
    "#When there are more than 20 negative values in one observation, we set it to be 20 (Why?)\n",
    "data.loc[data['neg1']>20,'neg1'] = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data['work_status'] = data['work_status'].fillna(0)\n",
    "data['work_yr'] = data['work_yr'].fillna(0)\n",
    "data['work_manage'] = data['work_manage'].fillna(0)\n",
    "data['work_type'] = data['work_type'].fillna(0)\n",
    "\n",
    "data['edu_yr'] = data['edu_yr'].fillna(0)\n",
    "data['edu_status'] = data['edu_status'].fillna(0)\n",
    "\n",
    "data['s_work_type'] = data['s_work_type'].fillna(0)\n",
    "data['s_work_status'] = data['s_work_status'].fillna(0)\n",
    "data['s_political'] = data['s_political'].fillna(0)\n",
    "data['s_hukou'] = data['s_hukou'].fillna(0)\n",
    "data['s_income'] = data['s_income'].fillna(0)\n",
    "data['s_birth'] = data['s_birth'].fillna(0)\n",
    "data['s_edu'] = data['s_edu'].fillna(0)\n",
    "data['s_work_exper'] = data['s_work_exper'].fillna(0)\n",
    "\n",
    "data['minor_child'] = data['minor_child'].fillna(0)\n",
    "data['marital_now'] = data['marital_now'].fillna(0)\n",
    "data['marital_1st'] = data['marital_1st'].fillna(0)\n",
    "data['social_neighbor']=data['social_neighbor'].fillna(0)\n",
    "data['social_friend']=data['social_friend'].fillna(0)\n",
    "data['hukou_loc']=data['hukou_loc'].fillna(1) \n",
    "#Use mean to fill\n",
    "data['family_income']=data['family_income'].fillna(66365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survey_time'] = pd.to_datetime(data['survey_time'], format='%Y-%m-%d',errors='coerce')\n",
    "data['survey_time'] = data['survey_time'].dt.year\n",
    "#The age while doing the survey\n",
    "data['age'] = data['survey_time']-data['birth']\n",
    "\n",
    "#Categorize the age to be 6 categories: 0-17/18-26/27-34/....\n",
    "bins = [0,17,26,34,50,63,100]\n",
    "data['age_bin'] = pd.cut(data['age'], bins, labels=[0,1,2,3,4,5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: when dealing with the missing value, here used some subjective standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['height_cm'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Religion, if less than 0 - no religion\n",
    "data.loc[data['religion']<0,'religion'] = 1 \n",
    "data.loc[data['religion_freq']<0,'religion_freq'] = 1 \n",
    "\n",
    "#Education level - if less than 0, set to be middle school. (But there are people especially cohort born before 1950, it is likely that their highest education level is primary school)\n",
    "data.loc[data['edu']<0,'edu'] = 4 #Middle school\n",
    "data.loc[data['edu_status']<0,'edu_status'] = 0\n",
    "data.loc[data['edu_yr']<0,'edu_yr'] = 0\n",
    "\n",
    "#Why there are negative value for income? 'Prefer not to say' or 'no income'?\n",
    "data.loc[data['income']<0,'income'] = 0 \n",
    "\n",
    "data.loc[data['political']<0,'political'] = 1 #Default not in the party\n",
    "\n",
    "\n",
    "data.loc[(data['weight_jin']<=80)&(data['height_cm']>=160),'weight_jin']= data['weight_jin']*2\n",
    "# data.loc[data['weight_jin']<=60,'weight_jin']= data['weight_jin']*2  #Data integrity\n",
    "\n",
    "# Minimum value of height_cm is 100, which makes sense\n",
    "# data.loc[data['height_cm']<150,'height_cm'] = 150 \n",
    "\n",
    "#Health\n",
    "data.loc[data['health']<0,'health'] = 3 \n",
    "data.loc[data['health_problem']<0,'health_problem'] = 3\n",
    "\n",
    "data.loc[data['depression']<0,'depression'] = 3 \n",
    "\n",
    "data.loc[data['media_1']<0,'media_1'] = 1 \n",
    "data.loc[data['media_2']<0,'media_2'] = 1\n",
    "data.loc[data['media_3']<0,'media_3'] = 1\n",
    "data.loc[data['media_4']<0,'media_4'] = 1\n",
    "data.loc[data['media_5']<0,'media_5'] = 1\n",
    "data.loc[data['media_6']<0,'media_6'] = 1\n",
    "\n",
    "data.loc[data['leisure_1']<0,'leisure_1'] = 1 \n",
    "data.loc[data['leisure_2']<0,'leisure_2'] = 5\n",
    "data.loc[data['leisure_3']<0,'leisure_3'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing value in categorical data - mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['leisure_4']<0,'leisure_4'] = data['leisure_4'].mode() \n",
    "data.loc[data['leisure_5']<0,'leisure_5'] = data['leisure_5'].mode()\n",
    "data.loc[data['leisure_6']<0,'leisure_6'] = data['leisure_6'].mode()\n",
    "data.loc[data['leisure_7']<0,'leisure_7'] = data['leisure_7'].mode()\n",
    "data.loc[data['leisure_8']<0,'leisure_8'] = data['leisure_8'].mode()\n",
    "data.loc[data['leisure_9']<0,'leisure_9'] = data['leisure_9'].mode()\n",
    "data.loc[data['leisure_10']<0,'leisure_10'] = data['leisure_10'].mode()\n",
    "data.loc[data['leisure_11']<0,'leisure_11'] = data['leisure_11'].mode()\n",
    "data.loc[data['leisure_12']<0,'leisure_12'] = data['leisure_12'].mode()\n",
    "data.loc[data['socialize']<0,'socialize'] = data['socialize'].mode()\n",
    "data.loc[data['relax']<0,'relax'] = data['relax'].mode()\n",
    "data.loc[data['learn']<0,'learn'] = data['learn'].mode()\n",
    "\n",
    "data.loc[data['social_neighbor']<0,'social_neighbor'] = 0\n",
    "data.loc[data['social_friend']<0,'social_friend'] = 0\n",
    "data.loc[data['socia_outing']<0,'socia_outing'] = 1\n",
    "data.loc[data['neighbor_familiarity']<0,'neighbor_familiarity']= 4\n",
    "\n",
    "data.loc[data['equity']<0,'equity'] = 4\n",
    "\n",
    "data.loc[data['class_10_before']<0,'class_10_before'] = 3\n",
    "data.loc[data['class']<0,'class'] = 5\n",
    "data.loc[data['class_10_after']<0,'class_10_after'] = 5\n",
    "data.loc[data['class_14']<0,'class_14'] = 2\n",
    "\n",
    "data.loc[data['work_status']<0,'work_status'] = 0\n",
    "data.loc[data['work_yr']<0,'work_yr'] = 0\n",
    "data.loc[data['work_manage']<0,'work_manage'] = 0\n",
    "data.loc[data['work_type']<0,'work_type'] = 0\n",
    "\n",
    "data.loc[data['insur_1']<0,'insur_1'] = 1\n",
    "data.loc[data['insur_2']<0,'insur_2'] = 1\n",
    "data.loc[data['insur_3']<0,'insur_3'] = 1\n",
    "data.loc[data['insur_4']<0,'insur_4'] = 1\n",
    "data.loc[data['insur_1']==0,'insur_1'] = 0\n",
    "data.loc[data['insur_2']==0,'insur_2'] = 0\n",
    "data.loc[data['insur_3']==0,'insur_3'] = 0\n",
    "data.loc[data['insur_4']==0,'insur_4'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing continuous data - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72464.02361969305"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['family_income'] >=0]['family_income'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['family_income']<0,'family_income'] = data[data['family_income'] >=0]['family_income'].mean()\n",
    "data.loc[data['family_m']<0,'family_m'] = 1\n",
    "data.loc[data['family_status']<0,'family_status'] = data['family_status'].mode()\n",
    "data.loc[data['house']<0,'house'] = 1\n",
    "data.loc[data['car']<0,'car'] = 0\n",
    "data.loc[data['car']==2,'car'] = 0 \n",
    "data.loc[data['son']<0,'son'] = 0\n",
    "data.loc[data['daughter']<0,'daughter'] = 0\n",
    "data.loc[data['minor_child']<0,'minor_child'] = 0\n",
    "\n",
    "data.loc[data['marital_1st']<0,'marital_1st'] = 0\n",
    "data.loc[data['marital_now']<0,'marital_now'] = 0\n",
    "\n",
    "data.loc[data['s_birth']<0,'s_birth'] = 0\n",
    "data.loc[data['s_edu']<0,'s_edu'] = 0\n",
    "data.loc[data['s_political']<0,'s_political'] = 0\n",
    "data.loc[data['s_hukou']<0,'s_hukou'] = 0\n",
    "data.loc[data['s_income']<0,'s_income'] = 0\n",
    "data.loc[data['s_work_type']<0,'s_work_type'] = 0\n",
    "data.loc[data['s_work_status']<0,'s_work_status'] = 0\n",
    "data.loc[data['s_work_exper']<0,'s_work_exper'] = 0\n",
    "\n",
    "data.loc[data['f_birth']<0,'f_birth'] = data[data['f_birth'] >=0]['f_birth'].mean()\n",
    "data.loc[data['f_edu']<0,'f_edu'] = 1\n",
    "data.loc[data['f_political']<0,'f_political'] = 1\n",
    "data.loc[data['f_work_14']<0,'f_work_14'] = 2\n",
    "data.loc[data['m_birth']<0,'m_birth'] = data[data['m_birth'] >=0]['m_birth'].mean()\n",
    "data.loc[data['m_edu']<0,'m_edu'] = 1\n",
    "data.loc[data['m_political']<0,'m_political'] = 1\n",
    "data.loc[data['m_work_14']<0,'m_work_14'] = 2\n",
    "\n",
    "data.loc[data['status_peer']<0,'status_peer'] = 2\n",
    "\n",
    "data.loc[data['status_3_before']<0,'status_3_before'] = 2\n",
    "\n",
    "data.loc[data['view']<0,'view'] = data[data['view'] >=0]['view'].mean()\n",
    "\n",
    "data.loc[data['inc_ability']<=0,'inc_ability']= data[data['inc_ability'] >=0]['inc_ability'].mean()\n",
    "\n",
    "data.loc[data['inc_exp']<=0,'inc_exp']= data[data['inc_exp'] >=0]['inc_exp'].mean()\n",
    "\n",
    "for i in range(1,9+1):\n",
    "    data.loc[data['public_service_'+str(i)]<0,'public_service_'+str(i)] = data['public_service_'+str(i)].dropna().mode().values\n",
    "for i in range(1,13+1):\n",
    "    data.loc[data['trust_'+str(i)]<0,'trust_'+str(i)] = data['trust_'+str(i)].dropna().mode().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['marital_1stbir'] = data['marital_1st'] - data['birth'] \n",
    "\n",
    "data['marital_nowtbir'] = data['marital_now'] - data['birth'] \n",
    "\n",
    "data['mar'] = data['marital_nowtbir'] - data['marital_1stbir']\n",
    "\n",
    "data['marital_sbir'] = data['marital_now']-data['s_birth']\n",
    "\n",
    "data['age_'] = data['marital_nowtbir'] - data['marital_sbir'] \n",
    "\n",
    "\n",
    "data['income/s_income'] = data['income']/(data['s_income']+1)\n",
    "data['income+s_income'] = data['income']+(data['s_income']+1)\n",
    "data['income/family_income'] = data['income']/(data['family_income']+1)\n",
    "data['all_income/family_income'] = (data['income']+data['s_income'])/(data['family_income']+1)\n",
    "data['income/inc_exp'] = data['income']/(data['inc_exp']+1)\n",
    "data['family_income/m'] = data['family_income']/(data['family_m']+0.01)\n",
    "data['income/m'] = data['income']/(data['family_m']+0.01)\n",
    "\n",
    "data['income/floor_area'] = data['income']/(data['floor_area']+0.01)\n",
    "data['all_income/floor_area'] = (data['income']+data['s_income'])/(data['floor_area']+0.01)\n",
    "data['family_income/floor_area'] = data['family_income']/(data['floor_area']+0.01)\n",
    "data['floor_area/m'] = data['floor_area']/(data['family_m']+0.01)\n",
    "\n",
    "data['class_10_diff'] = (data['class_10_after'] - data['class'])\n",
    "data['class_diff'] = data['class'] - data['class_10_before']\n",
    "data['class_14_diff'] = data['class'] - data['class_14']\n",
    "\n",
    "leisure_fea_lis = ['leisure_'+str(i) for i in range(1,13)]\n",
    "data['leisure_sum'] = data[leisure_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "public_service_fea_lis = ['public_service_'+str(i) for i in range(1,10)]\n",
    "data['public_service_sum'] = data[public_service_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "trust_fea_lis = ['trust_'+str(i) for i in range(1,14)]\n",
    "data['trust_sum'] = data[trust_fea_lis].sum(axis=1) #skew\n",
    "\n",
    "data['province_income_mean'] = data.groupby(['province'])['income'].transform('mean').values\n",
    "data['province_family_income_mean'] = data.groupby(['province'])['family_income'].transform('mean').values\n",
    "data['province_equity_mean'] = data.groupby(['province'])['equity'].transform('mean').values\n",
    "data['province_depression_mean'] = data.groupby(['province'])['depression'].transform('mean').values\n",
    "data['province_floor_area_mean'] = data.groupby(['province'])['floor_area'].transform('mean').values\n",
    "data['province_health_mean'] = data.groupby(['province'])['health'].transform('mean').values\n",
    "data['province_class_10_diff_mean'] = data.groupby(['province'])['class_10_diff'].transform('mean').values\n",
    "data['province_class_mean'] = data.groupby(['province'])['class'].transform('mean').values\n",
    "data['province_health_problem_mean'] = data.groupby(['province'])['health_problem'].transform('mean').values\n",
    "data['province_family_status_mean'] = data.groupby(['province'])['family_status'].transform('mean').values\n",
    "data['province_leisure_sum_mean'] = data.groupby(['province'])['leisure_sum'].transform('mean').values\n",
    "data['province_public_service_sum_mean'] = data.groupby(['province'])['public_service_sum'].transform('mean').values\n",
    "data['province_trust_sum_mean'] = data.groupby(['province'])['trust_sum'].transform('mean').values\n",
    "\n",
    "#city   mean 181+13=194\n",
    "data['city_income_mean'] = data.groupby(['city'])['income'].transform('mean').values #按照city分组\n",
    "data['city_family_income_mean'] = data.groupby(['city'])['family_income'].transform('mean').values\n",
    "data['city_equity_mean'] = data.groupby(['city'])['equity'].transform('mean').values\n",
    "data['city_depression_mean'] = data.groupby(['city'])['depression'].transform('mean').values\n",
    "data['city_floor_area_mean'] = data.groupby(['city'])['floor_area'].transform('mean').values\n",
    "data['city_health_mean'] = data.groupby(['city'])['health'].transform('mean').values\n",
    "data['city_class_10_diff_mean'] = data.groupby(['city'])['class_10_diff'].transform('mean').values\n",
    "data['city_class_mean'] = data.groupby(['city'])['class'].transform('mean').values\n",
    "data['city_health_problem_mean'] = data.groupby(['city'])['health_problem'].transform('mean').values\n",
    "data['city_family_status_mean'] = data.groupby(['city'])['family_status'].transform('mean').values\n",
    "data['city_leisure_sum_mean'] = data.groupby(['city'])['leisure_sum'].transform('mean').values\n",
    "data['city_public_service_sum_mean'] = data.groupby(['city'])['public_service_sum'].transform('mean').values\n",
    "data['city_trust_sum_mean'] = data.groupby(['city'])['trust_sum'].transform('mean').values\n",
    "\n",
    "data['county_income_mean'] = data.groupby(['county'])['income'].transform('mean').values\n",
    "data['county_family_income_mean'] = data.groupby(['county'])['family_income'].transform('mean').values\n",
    "data['county_equity_mean'] = data.groupby(['county'])['equity'].transform('mean').values\n",
    "data['county_depression_mean'] = data.groupby(['county'])['depression'].transform('mean').values\n",
    "data['county_floor_area_mean'] = data.groupby(['county'])['floor_area'].transform('mean').values\n",
    "data['county_health_mean'] = data.groupby(['county'])['health'].transform('mean').values\n",
    "data['county_class_10_diff_mean'] = data.groupby(['county'])['class_10_diff'].transform('mean').values\n",
    "data['county_class_mean'] = data.groupby(['county'])['class'].transform('mean').values\n",
    "data['county_health_problem_mean'] = data.groupby(['county'])['health_problem'].transform('mean').values\n",
    "data['county_family_status_mean'] = data.groupby(['county'])['family_status'].transform('mean').values\n",
    "data['county_leisure_sum_mean'] = data.groupby(['county'])['leisure_sum'].transform('mean').values\n",
    "data['county_public_service_sum_mean'] = data.groupby(['county'])['public_service_sum'].transform('mean').values\n",
    "data['county_trust_sum_mean'] = data.groupby(['county'])['trust_sum'].transform('mean').values\n",
    "\n",
    "data['income/province'] = data['income']/(data['province_income_mean'])                                      \n",
    "data['family_income/province'] = data['family_income']/(data['province_family_income_mean'])   \n",
    "data['equity/province'] = data['equity']/(data['province_equity_mean'])       \n",
    "data['depression/province'] = data['depression']/(data['province_depression_mean'])                                                \n",
    "data['floor_area/province'] = data['floor_area']/(data['province_floor_area_mean'])\n",
    "data['health/province'] = data['health']/(data['province_health_mean'])\n",
    "data['class_10_diff/province'] = data['class_10_diff']/(data['province_class_10_diff_mean'])\n",
    "data['class/province'] = data['class']/(data['province_class_mean'])\n",
    "data['health_problem/province'] = data['health_problem']/(data['province_health_problem_mean'])\n",
    "data['family_status/province'] = data['family_status']/(data['province_family_status_mean'])\n",
    "data['leisure_sum/province'] = data['leisure_sum']/(data['province_leisure_sum_mean'])\n",
    "data['public_service_sum/province'] = data['public_service_sum']/(data['province_public_service_sum_mean'])\n",
    "data['trust_sum/province'] = data['trust_sum']/(data['province_trust_sum_mean']+1)\n",
    "\n",
    "data['income/city'] = data['income']/(data['city_income_mean'])                                      \n",
    "data['family_income/city'] = data['family_income']/(data['city_family_income_mean'])   \n",
    "data['equity/city'] = data['equity']/(data['city_equity_mean'])       \n",
    "data['depression/city'] = data['depression']/(data['city_depression_mean'])                                                \n",
    "data['floor_area/city'] = data['floor_area']/(data['city_floor_area_mean'])\n",
    "data['health/city'] = data['health']/(data['city_health_mean'])\n",
    "data['class_10_diff/city'] = data['class_10_diff']/(data['city_class_10_diff_mean'])\n",
    "data['class/city'] = data['class']/(data['city_class_mean'])\n",
    "data['health_problem/city'] = data['health_problem']/(data['city_health_problem_mean'])\n",
    "data['family_status/city'] = data['family_status']/(data['city_family_status_mean'])\n",
    "data['leisure_sum/city'] = data['leisure_sum']/(data['city_leisure_sum_mean'])\n",
    "data['public_service_sum/city'] = data['public_service_sum']/(data['city_public_service_sum_mean'])\n",
    "data['trust_sum/city'] = data['trust_sum']/(data['city_trust_sum_mean'])\n",
    "\n",
    "\n",
    "data['income/county'] = data['income']/(data['county_income_mean'])                                      \n",
    "data['family_income/county'] = data['family_income']/(data['county_family_income_mean'])   \n",
    "data['equity/county'] = data['equity']/(data['county_equity_mean'])       \n",
    "data['depression/county'] = data['depression']/(data['county_depression_mean'])                                                \n",
    "data['floor_area/county'] = data['floor_area']/(data['county_floor_area_mean'])\n",
    "data['health/county'] = data['health']/(data['county_health_mean'])\n",
    "data['class_10_diff/county'] = data['class_10_diff']/(data['county_class_10_diff_mean'])\n",
    "data['class/county'] = data['class']/(data['county_class_mean'])\n",
    "data['health_problem/county'] = data['health_problem']/(data['county_health_problem_mean'])\n",
    "data['family_status/county'] = data['family_status']/(data['county_family_status_mean'])\n",
    "data['leisure_sum/county'] = data['leisure_sum']/(data['county_leisure_sum_mean'])\n",
    "data['public_service_sum/county'] = data['public_service_sum']/(data['county_public_service_sum_mean'])\n",
    "data['trust_sum/county'] = data['trust_sum']/(data['county_trust_sum_mean'])\n",
    "\n",
    "\n",
    "data['age_income_mean'] = data.groupby(['age'])['income'].transform('mean').values\n",
    "data['age_family_income_mean'] = data.groupby(['age'])['family_income'].transform('mean').values\n",
    "data['age_equity_mean'] = data.groupby(['age'])['equity'].transform('mean').values\n",
    "data['age_depression_mean'] = data.groupby(['age'])['depression'].transform('mean').values\n",
    "data['age_floor_area_mean'] = data.groupby(['age'])['floor_area'].transform('mean').values\n",
    "data['age_health_mean'] = data.groupby(['age'])['health'].transform('mean').values\n",
    "data['age_class_10_diff_mean'] = data.groupby(['age'])['class_10_diff'].transform('mean').values\n",
    "data['age_class_mean'] = data.groupby(['age'])['class'].transform('mean').values\n",
    "data['age_health_problem_mean'] = data.groupby(['age'])['health_problem'].transform('mean').values\n",
    "data['age_family_status_mean'] = data.groupby(['age'])['family_status'].transform('mean').values\n",
    "data['age_leisure_sum_mean'] = data.groupby(['age'])['leisure_sum'].transform('mean').values\n",
    "data['age_public_service_sum_mean'] = data.groupby(['age'])['public_service_sum'].transform('mean').values\n",
    "data['age_trust_sum_mean'] = data.groupby(['age'])['trust_sum'].transform('mean').values\n",
    "\n",
    "\n",
    "data['income/age'] = data['income']/(data['age_income_mean'])                                      \n",
    "data['family_income/age'] = data['family_income']/(data['age_family_income_mean'])   \n",
    "data['equity/age'] = data['equity']/(data['age_equity_mean'])       \n",
    "data['depression/age'] = data['depression']/(data['age_depression_mean'])                                                \n",
    "data['floor_area/age'] = data['floor_area']/(data['age_floor_area_mean'])\n",
    "data['health/age'] = data['health']/(data['age_health_mean'])\n",
    "data['class_10_diff/age'] = data['class_10_diff']/(data['age_class_10_diff_mean'])\n",
    "data['class/age'] = data['class']/(data['age_class_mean'])\n",
    "data['health_problem/age'] = data['health_problem']/(data['age_health_problem_mean'])\n",
    "data['family_status/age'] = data['family_status']/(data['age_family_status_mean'])\n",
    "data['leisure_sum/age'] = data['leisure_sum']/(data['age_leisure_sum_mean'])\n",
    "data['public_service_sum/age'] = data['public_service_sum']/(data['age_public_service_sum_mean'])\n",
    "data['trust_sum/age'] = data['trust_sum']/(data['age_trust_sum_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (10956, 272)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey_type</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>survey_time</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>depression/age</th>\n",
       "      <th>floor_area/age</th>\n",
       "      <th>health/age</th>\n",
       "      <th>class_10_diff/age</th>\n",
       "      <th>class/age</th>\n",
       "      <th>health_problem/age</th>\n",
       "      <th>family_status/age</th>\n",
       "      <th>leisure_sum/age</th>\n",
       "      <th>public_service_sum/age</th>\n",
       "      <th>trust_sum/age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>59</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285211</td>\n",
       "      <td>0.410351</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683307</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.724620</td>\n",
       "      <td>0.666638</td>\n",
       "      <td>0.925941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.952824</td>\n",
       "      <td>1.179337</td>\n",
       "      <td>1.012552</td>\n",
       "      <td>1.344444</td>\n",
       "      <td>0.892989</td>\n",
       "      <td>1.359551</td>\n",
       "      <td>1.011792</td>\n",
       "      <td>1.130778</td>\n",
       "      <td>1.188442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>126</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343537</td>\n",
       "      <td>0.972328</td>\n",
       "      <td>1.150485</td>\n",
       "      <td>1.190955</td>\n",
       "      <td>1.195762</td>\n",
       "      <td>1.055679</td>\n",
       "      <td>1.192893</td>\n",
       "      <td>0.966470</td>\n",
       "      <td>1.193204</td>\n",
       "      <td>0.803693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1943</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111663</td>\n",
       "      <td>0.642329</td>\n",
       "      <td>1.276353</td>\n",
       "      <td>4.977778</td>\n",
       "      <td>1.199143</td>\n",
       "      <td>1.188329</td>\n",
       "      <td>1.166078</td>\n",
       "      <td>0.899346</td>\n",
       "      <td>1.153810</td>\n",
       "      <td>1.300950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.587284</td>\n",
       "      <td>1.177106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>1.116803</td>\n",
       "      <td>1.093645</td>\n",
       "      <td>1.045313</td>\n",
       "      <td>0.728161</td>\n",
       "      <td>1.117428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  survey_type  province  city  county  survey_time  gender  birth  \\\n",
       "0   1            1        12    32      59         2015       1   1959   \n",
       "1   2            2        18    52      85         2015       1   1992   \n",
       "2   3            2        29    83     126         2015       2   1967   \n",
       "3   4            2        10    28      51         2015       2   1943   \n",
       "4   5            1         7    18      36         2015       2   1994   \n",
       "\n",
       "   nationality  religion  ...  depression/age  floor_area/age health/age  \\\n",
       "0            1         1  ...        1.285211        0.410351   0.848837   \n",
       "1            1         1  ...        0.733333        0.952824   1.179337   \n",
       "2            1         0  ...        1.343537        0.972328   1.150485   \n",
       "3            1         1  ...        1.111663        0.642329   1.276353   \n",
       "4            1         1  ...        0.750000        0.587284   1.177106   \n",
       "\n",
       "   class_10_diff/age  class/age  health_problem/age  family_status/age  \\\n",
       "0           0.000000   0.683307            0.521429           0.734177   \n",
       "1           1.012552   1.344444            0.892989           1.359551   \n",
       "2           1.190955   1.195762            1.055679           1.192893   \n",
       "3           4.977778   1.199143            1.188329           1.166078   \n",
       "4           0.000000   0.236957            1.116803           1.093645   \n",
       "\n",
       "   leisure_sum/age  public_service_sum/age  trust_sum/age  \n",
       "0         0.724620                0.666638       0.925941  \n",
       "1         1.011792                1.130778       1.188442  \n",
       "2         0.966470                1.193204       0.803693  \n",
       "3         0.899346                1.153810       1.300950  \n",
       "4         1.045313                0.728161       1.117428  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape',data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 263)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_list=['id','survey_time','edu_other','invest_other','property_other','join_party','province','city','county']\n",
    "use_feature = [clo for clo in data.columns if clo not in del_list]\n",
    "data.fillna(0,inplace=True) \n",
    "train_shape = train.shape[0] \n",
    "features = data[use_feature].columns \n",
    "X_train_263 = data[:train_shape][use_feature].values\n",
    "y_train = target\n",
    "X_test_263 = data[train_shape:][use_feature].values\n",
    "X_train_263.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49 important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 49)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_fea_49 = ['equity','depression','health','class','family_status','health_problem','class_10_after',\n",
    "           'equity/province','equity/city','equity/county',\n",
    "           'depression/province','depression/city','depression/county',\n",
    "           'health/province','health/city','health/county',\n",
    "           'class/province','class/city','class/county',\n",
    "           'family_status/province','family_status/city','family_status/county',\n",
    "           'family_income/province','family_income/city','family_income/county',\n",
    "           'floor_area/province','floor_area/city','floor_area/county',\n",
    "           'leisure_sum/province','leisure_sum/city','leisure_sum/county',\n",
    "           'public_service_sum/province','public_service_sum/city','public_service_sum/county',\n",
    "           'trust_sum/province','trust_sum/city','trust_sum/county',\n",
    "           'income/m','public_service_sum','class_diff','status_3_before','age_income_mean','age_floor_area_mean',\n",
    "           'weight_jin','height_cm',\n",
    "           'health/age','depression/age','equity/age','leisure_sum/age'\n",
    "          ]\n",
    "train_shape = train.shape[0]\n",
    "X_train_49 = data[:train_shape][imp_fea_49].values\n",
    "X_test_49 = data[train_shape:][imp_fea_49].values\n",
    "X_train_49.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7988, 383)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_fea = ['survey_type','gender','nationality','edu_status','political','hukou','hukou_loc','work_exper','work_status','work_type',\n",
    "           'work_manage','marital','s_political','s_hukou','s_work_exper','s_work_status','s_work_type','f_political','f_work_14',\n",
    "           'm_political','m_work_14'] \n",
    "noc_fea = [clo for clo in use_feature if clo not in cat_fea]\n",
    "\n",
    "onehot_data = data[cat_fea].values\n",
    "enc = preprocessing.OneHotEncoder(categories = 'auto')\n",
    "oh_data=enc.fit_transform(onehot_data).toarray()\n",
    "oh_data.shape \n",
    "\n",
    "X_train_oh = oh_data[:train_shape,:]\n",
    "X_test_oh = oh_data[train_shape:,:]\n",
    "X_train_oh.shape \n",
    "\n",
    "X_train_383 = np.column_stack([data[:train_shape][noc_fea].values,X_train_oh])\n",
    "X_test_383 = np.column_stack([data[train_shape:][noc_fea].values,X_test_oh])\n",
    "X_train_383.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - 263 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LightGBM - 5 fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.499908\tvalid_1's l2: 0.529768\n",
      "[1000]\ttraining's l2: 0.451432\tvalid_1's l2: 0.496631\n",
      "[1500]\ttraining's l2: 0.425325\tvalid_1's l2: 0.483159\n",
      "[2000]\ttraining's l2: 0.407249\tvalid_1's l2: 0.476897\n",
      "[2500]\ttraining's l2: 0.392953\tvalid_1's l2: 0.473395\n",
      "[3000]\ttraining's l2: 0.380651\tvalid_1's l2: 0.471306\n",
      "[3500]\ttraining's l2: 0.369908\tvalid_1's l2: 0.47006\n",
      "[4000]\ttraining's l2: 0.360095\tvalid_1's l2: 0.469321\n",
      "[4500]\ttraining's l2: 0.351114\tvalid_1's l2: 0.468653\n",
      "[5000]\ttraining's l2: 0.342729\tvalid_1's l2: 0.468601\n",
      "[5500]\ttraining's l2: 0.334816\tvalid_1's l2: 0.46824\n",
      "[6000]\ttraining's l2: 0.327416\tvalid_1's l2: 0.46815\n",
      "[6500]\ttraining's l2: 0.320197\tvalid_1's l2: 0.467981\n",
      "[7000]\ttraining's l2: 0.313394\tvalid_1's l2: 0.468194\n",
      "Early stopping, best iteration is:\n",
      "[6507]\ttraining's l2: 0.320101\tvalid_1's l2: 0.46794\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.503942\tvalid_1's l2: 0.512676\n",
      "[1000]\ttraining's l2: 0.454501\tvalid_1's l2: 0.478612\n",
      "[1500]\ttraining's l2: 0.428221\tvalid_1's l2: 0.465755\n",
      "[2000]\ttraining's l2: 0.410487\tvalid_1's l2: 0.459143\n",
      "[2500]\ttraining's l2: 0.396665\tvalid_1's l2: 0.455587\n",
      "[3000]\ttraining's l2: 0.38471\tvalid_1's l2: 0.452858\n",
      "[3500]\ttraining's l2: 0.374194\tvalid_1's l2: 0.450884\n",
      "[4000]\ttraining's l2: 0.364589\tvalid_1's l2: 0.449325\n",
      "[4500]\ttraining's l2: 0.355653\tvalid_1's l2: 0.448284\n",
      "[5000]\ttraining's l2: 0.347363\tvalid_1's l2: 0.447298\n",
      "[5500]\ttraining's l2: 0.339353\tvalid_1's l2: 0.446541\n",
      "[6000]\ttraining's l2: 0.331725\tvalid_1's l2: 0.446215\n",
      "[6500]\ttraining's l2: 0.324446\tvalid_1's l2: 0.445829\n",
      "[7000]\ttraining's l2: 0.317531\tvalid_1's l2: 0.445709\n",
      "[7500]\ttraining's l2: 0.31082\tvalid_1's l2: 0.445234\n",
      "[8000]\ttraining's l2: 0.30449\tvalid_1's l2: 0.444832\n",
      "[8500]\ttraining's l2: 0.298351\tvalid_1's l2: 0.44449\n",
      "[9000]\ttraining's l2: 0.292413\tvalid_1's l2: 0.444119\n",
      "[9500]\ttraining's l2: 0.286667\tvalid_1's l2: 0.443972\n",
      "[10000]\ttraining's l2: 0.281134\tvalid_1's l2: 0.443761\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l2: 0.281134\tvalid_1's l2: 0.443761\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.502786\tvalid_1's l2: 0.518509\n",
      "[1000]\ttraining's l2: 0.454688\tvalid_1's l2: 0.480691\n",
      "[1500]\ttraining's l2: 0.429463\tvalid_1's l2: 0.464477\n",
      "[2000]\ttraining's l2: 0.412028\tvalid_1's l2: 0.455932\n",
      "[2500]\ttraining's l2: 0.397814\tvalid_1's l2: 0.450178\n",
      "[3000]\ttraining's l2: 0.385983\tvalid_1's l2: 0.446581\n",
      "[3500]\ttraining's l2: 0.375174\tvalid_1's l2: 0.444369\n",
      "[4000]\ttraining's l2: 0.365418\tvalid_1's l2: 0.442522\n",
      "[4500]\ttraining's l2: 0.356446\tvalid_1's l2: 0.441545\n",
      "[5000]\ttraining's l2: 0.348036\tvalid_1's l2: 0.44071\n",
      "[5500]\ttraining's l2: 0.339907\tvalid_1's l2: 0.439859\n",
      "[6000]\ttraining's l2: 0.33234\tvalid_1's l2: 0.439398\n",
      "[6500]\ttraining's l2: 0.325013\tvalid_1's l2: 0.439225\n",
      "[7000]\ttraining's l2: 0.318051\tvalid_1's l2: 0.439051\n",
      "Early stopping, best iteration is:\n",
      "[6678]\ttraining's l2: 0.322506\tvalid_1's l2: 0.439012\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.504074\tvalid_1's l2: 0.51297\n",
      "[1000]\ttraining's l2: 0.454985\tvalid_1's l2: 0.477827\n",
      "[1500]\ttraining's l2: 0.42838\tvalid_1's l2: 0.465155\n",
      "[2000]\ttraining's l2: 0.410368\tvalid_1's l2: 0.459267\n",
      "[2500]\ttraining's l2: 0.396083\tvalid_1's l2: 0.455949\n",
      "[3000]\ttraining's l2: 0.38406\tvalid_1's l2: 0.453743\n",
      "[3500]\ttraining's l2: 0.373501\tvalid_1's l2: 0.452369\n",
      "[4000]\ttraining's l2: 0.363819\tvalid_1's l2: 0.451478\n",
      "[4500]\ttraining's l2: 0.354804\tvalid_1's l2: 0.450384\n",
      "[5000]\ttraining's l2: 0.346295\tvalid_1's l2: 0.449842\n",
      "[5500]\ttraining's l2: 0.338394\tvalid_1's l2: 0.449315\n",
      "[6000]\ttraining's l2: 0.330775\tvalid_1's l2: 0.448898\n",
      "[6500]\ttraining's l2: 0.32354\tvalid_1's l2: 0.448711\n",
      "[7000]\ttraining's l2: 0.316676\tvalid_1's l2: 0.448398\n",
      "[7500]\ttraining's l2: 0.310051\tvalid_1's l2: 0.448316\n",
      "[8000]\ttraining's l2: 0.303624\tvalid_1's l2: 0.448392\n",
      "Early stopping, best iteration is:\n",
      "[7280]\ttraining's l2: 0.312985\tvalid_1's l2: 0.448191\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 800 rounds\n",
      "[500]\ttraining's l2: 0.502536\tvalid_1's l2: 0.520733\n",
      "[1000]\ttraining's l2: 0.454168\tvalid_1's l2: 0.485628\n",
      "[1500]\ttraining's l2: 0.428195\tvalid_1's l2: 0.471884\n",
      "[2000]\ttraining's l2: 0.410212\tvalid_1's l2: 0.465573\n",
      "[2500]\ttraining's l2: 0.395737\tvalid_1's l2: 0.461906\n",
      "[3000]\ttraining's l2: 0.383472\tvalid_1's l2: 0.459296\n",
      "[3500]\ttraining's l2: 0.372488\tvalid_1's l2: 0.457857\n",
      "[4000]\ttraining's l2: 0.362551\tvalid_1's l2: 0.457088\n",
      "[4500]\ttraining's l2: 0.35339\tvalid_1's l2: 0.457053\n",
      "Early stopping, best iteration is:\n",
      "[4188]\ttraining's l2: 0.359001\tvalid_1's l2: 0.456909\n",
      "CV score: 0.45116209\n"
     ]
    }
   ],
   "source": [
    "lgb_263_param = {\n",
    "'num_leaves': 7, \n",
    "'min_data_in_leaf': 20,\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.003,\n",
    "\"boosting\": \"gbdt\", \n",
    "\"feature_fraction\": 0.18, \n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.55, \n",
    "\"bagging_seed\": 14,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l1\": 0.1,\n",
    "\"lambda_l2\": 0.2, \n",
    "\"verbosity\": -1}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)   \n",
    "oof_lgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_lgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_263[val_idx], y_train[val_idx])#train:val=4:1\n",
    "\n",
    "    num_round = 10000\n",
    "    lgb_263 = lgb.train(lgb_263_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 800)\n",
    "    oof_lgb_263[val_idx] = lgb_263.predict(X_train_263[val_idx], num_iteration=lgb_263.best_iteration)\n",
    "    predictions_lgb_263 += lgb_263.predict(X_test_263, num_iteration=lgb_263.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x2016 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "pd.set_option('max_colwidth',100)\n",
    "df = pd.DataFrame(data[use_feature].columns.tolist(), columns=['feature'])\n",
    "df['importance']=list(lgb_263.feature_importance())\n",
    "df = df.sort_values(by='importance',ascending=False)\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df.head(50))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[01:11:31] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:11:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40000\tvalid_data-rmse:3.40006\n",
      "[500]\ttrain-rmse:0.40641\tvalid_data-rmse:0.68302\n",
      "[1000]\ttrain-rmse:0.27408\tvalid_data-rmse:0.68254\n",
      "[1350]\ttrain-rmse:0.20713\tvalid_data-rmse:0.68486\n",
      "fold n°2\n",
      "[01:12:13] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:12:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39999\tvalid_data-rmse:3.40007\n",
      "[500]\ttrain-rmse:0.40940\tvalid_data-rmse:0.67823\n",
      "[1000]\ttrain-rmse:0.27583\tvalid_data-rmse:0.68026\n",
      "[1130]\ttrain-rmse:0.24854\tvalid_data-rmse:0.68052\n",
      "fold n°3\n",
      "[01:12:47] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:12:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39995\tvalid_data-rmse:3.40024\n",
      "[500]\ttrain-rmse:0.40913\tvalid_data-rmse:0.67361\n",
      "[1000]\ttrain-rmse:0.27205\tvalid_data-rmse:0.67504\n",
      "[1171]\ttrain-rmse:0.23644\tvalid_data-rmse:0.67501\n",
      "fold n°4\n",
      "[01:13:23] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:13:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40012\tvalid_data-rmse:3.40044\n",
      "[500]\ttrain-rmse:0.41033\tvalid_data-rmse:0.67241\n",
      "[1000]\ttrain-rmse:0.27641\tvalid_data-rmse:0.67176\n",
      "[1332]\ttrain-rmse:0.21202\tvalid_data-rmse:0.67275\n",
      "fold n°5\n",
      "[01:14:04] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:14:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40024\tvalid_data-rmse:3.40001\n",
      "[500]\ttrain-rmse:0.41073\tvalid_data-rmse:0.66178\n",
      "[986]\ttrain-rmse:0.27824\tvalid_data-rmse:0.66448\n",
      "CV score: 0.45274020\n"
     ]
    }
   ],
   "source": [
    "xgb_263_params = {'eta': 0.02,  \n",
    "              'max_depth': 6,  \n",
    "              'min_child_weight':3,\n",
    "              'gamma':0,\n",
    "              'subsample': 0.7,  \n",
    "              'colsample_bytree': 0.3, \n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_263 = np.zeros(len(X_train_263))\n",
    "predictions_xgb_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_263[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_263[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_263 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_263_params)\n",
    "    oof_xgb_263[val_idx] = xgb_263.predict(xgb.DMatrix(X_train_263[val_idx]), ntree_limit=xgb_263.best_ntree_limit)\n",
    "    predictions_xgb_263 += xgb_263.predict(xgb.DMatrix(X_test_263), ntree_limit=xgb_263.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   58.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   56.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   57.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   56.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:   57.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.47780150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_rfr_263 = np.zeros(len(X_train_263))\n",
    "predictions_rfr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    rfr_263 = rfr(n_estimators=1600,max_depth=9, min_samples_leaf=9, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.25,verbose=1,n_jobs=-1) \n",
    "    #verbose = 0 \n",
    "#verbose = 1 \n",
    "#verbose = 2 \n",
    "    rfr_263.fit(tr_x,tr_y)\n",
    "    oof_rfr_263[val_idx] = rfr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_rfr_263 += rfr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_rfr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6643           0.0036           29.56s\n",
      "         2           0.6718           0.0028           28.87s\n",
      "         3           0.6466           0.0031           28.55s\n",
      "         4           0.6430           0.0033           31.76s\n",
      "         5           0.6443           0.0031           30.94s\n",
      "         6           0.6405           0.0032           32.23s\n",
      "         7           0.6396           0.0030           33.47s\n",
      "         8           0.6301           0.0031           33.23s\n",
      "         9           0.6226           0.0028           34.87s\n",
      "        10           0.6266           0.0028           34.18s\n",
      "        20           0.5830           0.0023           30.77s\n",
      "        30           0.5908           0.0017           28.88s\n",
      "        40           0.5286           0.0017           27.77s\n",
      "        50           0.5056           0.0014           26.84s\n",
      "        60           0.4886           0.0012           25.90s\n",
      "        70           0.4762           0.0010           25.02s\n",
      "        80           0.4558           0.0007           24.10s\n",
      "        90           0.4453           0.0008           23.37s\n",
      "       100           0.4274           0.0005           22.55s\n",
      "       200           0.3483           0.0001           14.53s\n",
      "       300           0.2892           0.0000            7.18s\n",
      "       400           0.2770           0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6760           0.0034           33.44s\n",
      "         2           0.6557           0.0033           31.22s\n",
      "         3           0.6523           0.0033           39.62s\n",
      "         4           0.6445           0.0031           36.35s\n",
      "         5           0.6365           0.0034           34.89s\n",
      "         6           0.6451           0.0030           34.89s\n",
      "         7           0.6314           0.0030           36.69s\n",
      "         8           0.6413           0.0026           35.57s\n",
      "         9           0.6358           0.0031           35.45s\n",
      "        10           0.6357           0.0029           36.26s\n",
      "        20           0.5858           0.0024           31.79s\n",
      "        30           0.5631           0.0019           29.58s\n",
      "        40           0.5313           0.0015           27.96s\n",
      "        50           0.5149           0.0014           26.95s\n",
      "        60           0.5037           0.0014           25.90s\n",
      "        70           0.4763           0.0009           25.22s\n",
      "        80           0.4557           0.0008           24.62s\n",
      "        90           0.4270           0.0007           24.09s\n",
      "       100           0.4231           0.0006           23.19s\n",
      "       200           0.3366           0.0003           14.20s\n",
      "       300           0.2912           0.0001            6.63s\n",
      "       400           0.2613          -0.0000            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6866           0.0034           22.64s\n",
      "         2           0.6740           0.0035           21.98s\n",
      "         3           0.6599           0.0032           22.18s\n",
      "         4           0.6740           0.0030           23.95s\n",
      "         5           0.6431           0.0033           25.83s\n",
      "         6           0.6323           0.0032           25.16s\n",
      "         7           0.6354           0.0032           24.70s\n",
      "         8           0.6431           0.0027           25.79s\n",
      "         9           0.6181           0.0032           25.48s\n",
      "        10           0.6233           0.0028           25.13s\n",
      "        20           0.5894           0.0023           23.72s\n",
      "        30           0.5673           0.0021           22.83s\n",
      "        40           0.5308           0.0017           22.11s\n",
      "        50           0.4958           0.0013           21.41s\n",
      "        60           0.4905           0.0011           20.72s\n",
      "        70           0.4769           0.0008           20.03s\n",
      "        80           0.4558           0.0008           19.42s\n",
      "        90           0.4341           0.0006           18.87s\n",
      "       100           0.4166           0.0007           18.20s\n",
      "       200           0.3439           0.0001           11.70s\n",
      "       300           0.2986           0.0000            5.80s\n",
      "       400           0.2633           0.0000            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6593           0.0033           26.07s\n",
      "         2           0.6546           0.0035           24.80s\n",
      "         3           0.6719           0.0031           23.82s\n",
      "         4           0.6670           0.0032           24.96s\n",
      "         5           0.6495           0.0033           25.90s\n",
      "         6           0.6480           0.0032           25.23s\n",
      "         7           0.6525           0.0030           24.72s\n",
      "         8           0.6372           0.0030           25.31s\n",
      "         9           0.6195           0.0029           25.59s\n",
      "        10           0.6189           0.0029           25.23s\n",
      "        20           0.6105           0.0022           23.86s\n",
      "        30           0.5611           0.0020           22.91s\n",
      "        40           0.5380           0.0016           22.07s\n",
      "        50           0.5175           0.0012           21.44s\n",
      "        60           0.4606           0.0011           20.72s\n",
      "        70           0.4641           0.0008           20.08s\n",
      "        80           0.4405           0.0009           19.45s\n",
      "        90           0.4435           0.0007           18.83s\n",
      "       100           0.4296           0.0006           18.20s\n",
      "       200           0.3345           0.0000           11.73s\n",
      "       300           0.2995           0.0000            5.82s\n",
      "       400           0.2674          -0.0000            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6749           0.0031           31.49s\n",
      "         2           0.6467           0.0035           31.65s\n",
      "         3           0.6615           0.0035           28.54s\n",
      "         4           0.6728           0.0031           27.07s\n",
      "         5           0.6449           0.0031           27.77s\n",
      "         6           0.6666           0.0030           28.01s\n",
      "         7           0.6199           0.0032           27.08s\n",
      "         8           0.6239           0.0029           26.36s\n",
      "         9           0.6265           0.0028           26.43s\n",
      "        10           0.6055           0.0031           27.02s\n",
      "        20           0.5944           0.0024           25.42s\n",
      "        30           0.5602           0.0020           25.91s\n",
      "        40           0.5401           0.0017           24.22s\n",
      "        50           0.5206           0.0013           22.84s\n",
      "        60           0.4988           0.0012           21.86s\n",
      "        70           0.4915           0.0010           21.05s\n",
      "        80           0.4348           0.0010           20.21s\n",
      "        90           0.4465           0.0005           19.42s\n",
      "       100           0.4247           0.0004           18.64s\n",
      "       200           0.3469           0.0001           11.85s\n",
      "       300           0.2891           0.0000            5.85s\n",
      "       400           0.2673           0.0000            0.00s\n",
      "CV score: 0.45470726\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_263 = np.zeros(train_shape)\n",
    "predictions_gbr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_263 = gbr(n_estimators=400, learning_rate=0.01,subsample=0.65,max_depth=7, min_samples_leaf=20,\n",
    "            max_features=0.22,verbose=1)\n",
    "    gbr_263.fit(tr_x,tr_y)\n",
    "    oof_gbr_263[val_idx] = gbr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_gbr_263 += gbr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   28.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   28.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   29.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   29.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   29.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.48560807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_etr_263 = np.zeros(train_shape)\n",
    "predictions_etr_263 = np.zeros(len(X_test_263))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_263, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_263[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    etr_263 = etr(n_estimators=1000,max_depth=8, min_samples_leaf=12, min_weight_fraction_leaf=0.0,\n",
    "            max_features=0.4,verbose=1,n_jobs=-1)\n",
    "    etr_263.fit(tr_x,tr_y)\n",
    "    oof_etr_263[val_idx] = etr_263.predict(X_train_263[val_idx])\n",
    "    \n",
    "    predictions_etr_263 += etr_263.predict(X_test_263) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_etr_263, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling & Feature Engineering - 49 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.470708\tvalid_1's l2: 0.49533\n",
      "[2000]\ttraining's l2: 0.430792\tvalid_1's l2: 0.475723\n",
      "[3000]\ttraining's l2: 0.408352\tvalid_1's l2: 0.470283\n",
      "[4000]\ttraining's l2: 0.390566\tvalid_1's l2: 0.467745\n",
      "[5000]\ttraining's l2: 0.375195\tvalid_1's l2: 0.466929\n",
      "[6000]\ttraining's l2: 0.36138\tvalid_1's l2: 0.466331\n",
      "[7000]\ttraining's l2: 0.348785\tvalid_1's l2: 0.466362\n",
      "Early stopping, best iteration is:\n",
      "[6501]\ttraining's l2: 0.354929\tvalid_1's l2: 0.466144\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.470545\tvalid_1's l2: 0.494825\n",
      "[2000]\ttraining's l2: 0.429727\tvalid_1's l2: 0.475862\n",
      "[3000]\ttraining's l2: 0.40708\tvalid_1's l2: 0.471551\n",
      "[4000]\ttraining's l2: 0.389121\tvalid_1's l2: 0.469654\n",
      "[5000]\ttraining's l2: 0.373686\tvalid_1's l2: 0.46918\n",
      "[6000]\ttraining's l2: 0.359722\tvalid_1's l2: 0.468886\n",
      "[7000]\ttraining's l2: 0.346965\tvalid_1's l2: 0.469111\n",
      "Early stopping, best iteration is:\n",
      "[6270]\ttraining's l2: 0.356212\tvalid_1's l2: 0.46873\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.473817\tvalid_1's l2: 0.486868\n",
      "[2000]\ttraining's l2: 0.432916\tvalid_1's l2: 0.463987\n",
      "[3000]\ttraining's l2: 0.409862\tvalid_1's l2: 0.45977\n",
      "[4000]\ttraining's l2: 0.391963\tvalid_1's l2: 0.459267\n",
      "Early stopping, best iteration is:\n",
      "[3581]\ttraining's l2: 0.398964\tvalid_1's l2: 0.459067\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.467453\tvalid_1's l2: 0.506157\n",
      "[2000]\ttraining's l2: 0.427734\tvalid_1's l2: 0.487989\n",
      "[3000]\ttraining's l2: 0.405938\tvalid_1's l2: 0.482703\n",
      "[4000]\ttraining's l2: 0.388516\tvalid_1's l2: 0.479893\n",
      "[5000]\ttraining's l2: 0.373592\tvalid_1's l2: 0.477979\n",
      "[6000]\ttraining's l2: 0.360348\tvalid_1's l2: 0.476099\n",
      "[7000]\ttraining's l2: 0.348106\tvalid_1's l2: 0.474507\n",
      "[8000]\ttraining's l2: 0.336668\tvalid_1's l2: 0.473431\n",
      "[9000]\ttraining's l2: 0.325903\tvalid_1's l2: 0.472694\n",
      "[10000]\ttraining's l2: 0.315893\tvalid_1's l2: 0.471945\n",
      "[11000]\ttraining's l2: 0.306348\tvalid_1's l2: 0.471507\n",
      "[12000]\ttraining's l2: 0.297339\tvalid_1's l2: 0.47098\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[12000]\ttraining's l2: 0.297339\tvalid_1's l2: 0.47098\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[1000]\ttraining's l2: 0.46928\tvalid_1's l2: 0.501034\n",
      "[2000]\ttraining's l2: 0.428616\tvalid_1's l2: 0.483187\n",
      "[3000]\ttraining's l2: 0.40604\tvalid_1's l2: 0.478915\n",
      "[4000]\ttraining's l2: 0.387937\tvalid_1's l2: 0.477565\n",
      "[5000]\ttraining's l2: 0.372545\tvalid_1's l2: 0.476637\n",
      "[6000]\ttraining's l2: 0.358689\tvalid_1's l2: 0.476453\n",
      "Early stopping, best iteration is:\n",
      "[5943]\ttraining's l2: 0.359451\tvalid_1's l2: 0.476381\n",
      "CV score: 0.46825906\n"
     ]
    }
   ],
   "source": [
    "lgb_49_param = {\n",
    "'num_leaves': 9,\n",
    "'min_data_in_leaf': 23,\n",
    "'objective':'regression',\n",
    "'max_depth': -1,\n",
    "'learning_rate': 0.002,\n",
    "\"boosting\": \"gbdt\",\n",
    "\"feature_fraction\": 0.45, \n",
    "\"bagging_freq\": 1,\n",
    "\"bagging_fraction\": 0.65, \n",
    "\"bagging_seed\": 15,\n",
    "\"metric\": 'mse',\n",
    "\"lambda_l2\": 0.2, \n",
    "\"verbosity\": -1} \n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=9)   \n",
    "oof_lgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_lgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 12000\n",
    "    lgb_49 = lgb.train(lgb_49_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n",
    "    oof_lgb_49[val_idx] = lgb_49.predict(X_train_49[val_idx], num_iteration=lgb_49.best_iteration)\n",
    "    predictions_lgb_49 += lgb_49.predict(X_test_49, num_iteration=lgb_49.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[00:50:53] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:50:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40427\tvalid_data-rmse:3.38313\n",
      "[500]\ttrain-rmse:0.52689\tvalid_data-rmse:0.72122\n",
      "[1000]\ttrain-rmse:0.43485\tvalid_data-rmse:0.72264\n",
      "[1163]\ttrain-rmse:0.40941\tvalid_data-rmse:0.72325\n",
      "fold n°2\n",
      "[00:51:06] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39815\tvalid_data-rmse:3.40775\n",
      "[500]\ttrain-rmse:0.52873\tvalid_data-rmse:0.70251\n",
      "[1000]\ttrain-rmse:0.43864\tvalid_data-rmse:0.70453\n",
      "[1129]\ttrain-rmse:0.41923\tvalid_data-rmse:0.70522\n",
      "fold n°3\n",
      "[00:51:18] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40182\tvalid_data-rmse:3.39292\n",
      "[500]\ttrain-rmse:0.53359\tvalid_data-rmse:0.66857\n",
      "[1000]\ttrain-rmse:0.44062\tvalid_data-rmse:0.67166\n",
      "[1027]\ttrain-rmse:0.43640\tvalid_data-rmse:0.67226\n",
      "fold n°4\n",
      "[00:51:29] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.40241\tvalid_data-rmse:3.39010\n",
      "[500]\ttrain-rmse:0.53255\tvalid_data-rmse:0.67770\n",
      "[1000]\ttrain-rmse:0.44371\tvalid_data-rmse:0.68044\n",
      "[1098]\ttrain-rmse:0.42784\tvalid_data-rmse:0.68151\n",
      "fold n°5\n",
      "[00:51:43] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:51:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:3.39345\tvalid_data-rmse:3.42630\n",
      "[500]\ttrain-rmse:0.53439\tvalid_data-rmse:0.66117\n",
      "[1000]\ttrain-rmse:0.44084\tvalid_data-rmse:0.66248\n",
      "[1344]\ttrain-rmse:0.39053\tvalid_data-rmse:0.66426\n",
      "CV score: 0.47091244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_49_params = {'eta': 0.02, \n",
    "              'max_depth': 5, \n",
    "              'min_child_weight':3,\n",
    "              'gamma':0,\n",
    "              'subsample': 0.7, \n",
    "              'colsample_bytree': 0.35, \n",
    "              'lambda':2,\n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              'nthread': -1}\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof_xgb_49 = np.zeros(len(X_train_49))\n",
    "predictions_xgb_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train_49[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train_49[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    xgb_49 = xgb.train(dtrain=trn_data, num_boost_round=3000, evals=watchlist, early_stopping_rounds=600, verbose_eval=500, params=xgb_49_params)\n",
    "    oof_xgb_49[val_idx] = xgb_49.predict(xgb.DMatrix(X_train_49[val_idx]), ntree_limit=xgb_49.best_ntree_limit)\n",
    "    predictions_xgb_49 += xgb_49.predict(xgb.DMatrix(X_test_49), ntree_limit=xgb_49.best_ntree_limit) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6589           0.0033           18.70s\n",
      "         2           0.6727           0.0033           18.76s\n",
      "         3           0.6633           0.0031           20.59s\n",
      "         4           0.6521           0.0031           20.65s\n",
      "         5           0.6546           0.0029           19.42s\n",
      "         6           0.6338           0.0032           18.58s\n",
      "         7           0.6464           0.0028           19.06s\n",
      "         8           0.6280           0.0030           20.19s\n",
      "         9           0.6492           0.0029           20.58s\n",
      "        10           0.6203           0.0029           19.85s\n",
      "        20           0.5951           0.0024           17.50s\n",
      "        30           0.5657           0.0022           22.89s\n",
      "        40           0.5556           0.0016           21.81s\n",
      "        50           0.5416           0.0012           20.54s\n",
      "        60           0.5237           0.0011           20.40s\n",
      "        70           0.4948           0.0009           19.50s\n",
      "        80           0.4865           0.0005           18.38s\n",
      "        90           0.4677           0.0006           18.27s\n",
      "       100           0.4608           0.0005           17.54s\n",
      "       200           0.3913           0.0001           13.70s\n",
      "       300           0.3709          -0.0000            9.65s\n",
      "       400           0.3419          -0.0000            6.24s\n",
      "       500           0.3246          -0.0000            3.01s\n",
      "       600           0.3323          -0.0000            0.00s\n",
      "fold n°2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6701           0.0032           16.88s\n",
      "         2           0.6552           0.0033           17.61s\n",
      "         3           0.6738           0.0028           17.57s\n",
      "         4           0.6577           0.0030           18.24s\n",
      "         5           0.6398           0.0031           18.70s\n",
      "         6           0.6555           0.0028           18.98s\n",
      "         7           0.6396           0.0031           18.57s\n",
      "         8           0.6354           0.0032           18.08s\n",
      "         9           0.6581           0.0028           17.92s\n",
      "        10           0.6362           0.0029           17.78s\n",
      "        20           0.6048           0.0022           18.08s\n",
      "        30           0.5654           0.0021           17.46s\n",
      "        40           0.5529           0.0015           16.82s\n",
      "        50           0.5281           0.0012           17.34s\n",
      "        60           0.4896           0.0010           16.40s\n",
      "        70           0.4843           0.0010           16.46s\n",
      "        80           0.4676           0.0008           15.89s\n",
      "        90           0.4749           0.0006           15.39s\n",
      "       100           0.4688           0.0005           14.81s\n",
      "       200           0.3915           0.0000           11.52s\n",
      "       300           0.3738           0.0000            8.82s\n",
      "       400           0.3492          -0.0001            6.06s\n",
      "       500           0.3256          -0.0001            3.00s\n",
      "       600           0.3081          -0.0000            0.00s\n",
      "fold n°3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6694           0.0030           14.11s\n",
      "         2           0.6523           0.0035           14.40s\n",
      "         3           0.6574           0.0032           14.25s\n",
      "         4           0.6706           0.0030           15.45s\n",
      "         5           0.6519           0.0032           17.84s\n",
      "         6           0.6554           0.0032           18.45s\n",
      "         7           0.6571           0.0030           19.14s\n",
      "         8           0.6281           0.0030           20.60s\n",
      "         9           0.6347           0.0027           20.35s\n",
      "        10           0.6221           0.0030           20.08s\n",
      "        20           0.5997           0.0024           19.91s\n",
      "        30           0.5695           0.0020           17.70s\n",
      "        40           0.5356           0.0015           17.22s\n",
      "        50           0.5305           0.0014           16.93s\n",
      "        60           0.5022           0.0012           16.33s\n",
      "        70           0.4981           0.0009           15.87s\n",
      "        80           0.4857           0.0008           15.32s\n",
      "        90           0.4580           0.0005           15.05s\n",
      "       100           0.4568           0.0006           14.50s\n",
      "       200           0.3946           0.0001           11.60s\n",
      "       300           0.3570           0.0000            8.65s\n",
      "       400           0.3372          -0.0000            5.54s\n",
      "       500           0.3207          -0.0001            2.76s\n",
      "       600           0.3065           0.0000            0.00s\n",
      "fold n°4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6722           0.0034           14.71s\n",
      "         2           0.6649           0.0034           14.95s\n",
      "         3           0.6788           0.0032           14.75s\n",
      "         4           0.6659           0.0032           15.54s\n",
      "         5           0.6433           0.0031           16.91s\n",
      "         6           0.6406           0.0029           18.90s\n",
      "         7           0.6502           0.0026           20.00s\n",
      "         8           0.6319           0.0028           20.25s\n",
      "         9           0.6453           0.0028           21.25s\n",
      "        10           0.6275           0.0029           21.71s\n",
      "        20           0.6084           0.0025           20.03s\n",
      "        30           0.5551           0.0020           19.93s\n",
      "        40           0.5491           0.0016           18.90s\n",
      "        50           0.5200           0.0013           18.41s\n",
      "        60           0.5082           0.0012           17.62s\n",
      "        70           0.4948           0.0009           18.18s\n",
      "        80           0.4833           0.0007           18.64s\n",
      "        90           0.4748           0.0008           18.68s\n",
      "       100           0.4593           0.0006           18.81s\n",
      "       200           0.3922           0.0001           13.64s\n",
      "       300           0.3691           0.0000            9.59s\n",
      "       400           0.3507          -0.0000            6.21s\n",
      "       500           0.3281           0.0000            3.10s\n",
      "       600           0.3156          -0.0001            0.00s\n",
      "fold n°5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.6608           0.0034           23.75s\n",
      "         2           0.6551           0.0034           22.30s\n",
      "         3           0.6666           0.0030           23.97s\n",
      "         4           0.6426           0.0030           23.45s\n",
      "         5           0.6658           0.0034           23.91s\n",
      "         6           0.6429           0.0031           23.68s\n",
      "         7           0.6211           0.0028           22.51s\n",
      "         8           0.6590           0.0029           22.63s\n",
      "         9           0.6375           0.0028           24.02s\n",
      "        10           0.6240           0.0028           24.35s\n",
      "        20           0.6062           0.0022           21.61s\n",
      "        30           0.5614           0.0018           20.68s\n",
      "        40           0.5606           0.0014           19.77s\n",
      "        50           0.5278           0.0013           19.73s\n",
      "        60           0.5207           0.0011           18.79s\n",
      "        70           0.5051           0.0008           17.93s\n",
      "        80           0.4879           0.0009           17.46s\n",
      "        90           0.4753           0.0005           16.74s\n",
      "       100           0.4661           0.0006           16.21s\n",
      "       200           0.3934           0.0001           11.91s\n",
      "       300           0.3681          -0.0000            9.07s\n",
      "       400           0.3370          -0.0001            5.90s\n",
      "       500           0.3261          -0.0000            2.99s\n",
      "       600           0.3033          -0.0000            0.00s\n",
      "CV score: 0.47075211\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_gbr_49 = np.zeros(train_shape)\n",
    "predictions_gbr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    gbr_49 = gbr(n_estimators=600, learning_rate=0.01,subsample=0.65,max_depth=6, min_samples_leaf=20,\n",
    "            max_features=0.35,verbose=1)\n",
    "    gbr_49.fit(tr_x,tr_y)\n",
    "    oof_gbr_49[val_idx] = gbr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_gbr_49 += gbr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_gbr_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4670808903788372"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack3 = np.vstack([oof_lgb_49,oof_xgb_49,oof_gbr_49]).transpose()\n",
    "test_stack3 = np.vstack([predictions_lgb_49, predictions_xgb_49,predictions_gbr_49]).transpose()\n",
    "#\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack3 = np.zeros(train_stack3.shape[0])\n",
    "predictions_lr3 = np.zeros(test_stack3.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack3,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack3[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack3[val_idx], target.iloc[val_idx].values\n",
    "        #Kernel Ridge Regression\n",
    "    lr3 = kr()\n",
    "    lr3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack3[val_idx] = lr3.predict(val_data)\n",
    "    predictions_lr3 += lr3.predict(test_stack3) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.50338056\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_49 = np.zeros(train_shape)\n",
    "predictions_kr_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    kr_49 = kr()\n",
    "    kr_49.fit(tr_x,tr_y)\n",
    "    oof_kr_49[val_idx] = kr_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_kr_49 += kr_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.49542586\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_49 = np.zeros(train_shape)\n",
    "predictions_ridge_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    ridge_49 = Ridge(alpha=6)\n",
    "    ridge_49.fit(tr_x,tr_y)\n",
    "    oof_ridge_49[val_idx] = ridge_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_ridge_49 += ridge_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.49625397\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_49 = np.zeros(train_shape)\n",
    "predictions_br_49 = np.zeros(len(X_test_49))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    br_49 = br()\n",
    "    br_49.fit(tr_x,tr_y)\n",
    "    oof_br_49[val_idx] = br_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_br_49 += br_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_49, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.53860666\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_49 = np.zeros(train_shape)\n",
    "predictions_en_49 = np.zeros(len(X_test_49))\n",
    "#\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_49, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_49[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    en_49 = en(alpha=1.0,l1_ratio=0.05)\n",
    "    en_49.fit(tr_x,tr_y)\n",
    "    oof_en_49[val_idx] = en_49.predict(X_train_49[val_idx])\n",
    "    \n",
    "    predictions_en_49 += en_49.predict(X_test_49) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_49, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4470559578172906"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack2 = np.vstack([oof_lgb_263,oof_xgb_263,oof_gbr_263,oof_rfr_263,oof_etr_263]).transpose()\n",
    "\n",
    "test_stack2 = np.vstack([predictions_lgb_263, predictions_xgb_263,predictions_gbr_263,predictions_rfr_263,predictions_etr_263]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack2 = np.zeros(train_stack2.shape[0])\n",
    "predictions_lr2 = np.zeros(test_stack2.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack2,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack2[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack2[val_idx], target.iloc[val_idx].values\n",
    "    #Kernel Ridge Regression\n",
    "    lr2 = kr()\n",
    "    lr2.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack2[val_idx] = lr2.predict(val_data)\n",
    "    predictions_lr2 += lr2.predict(test_stack2) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49585405823930767"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack4 = np.vstack([oof_br_49,oof_kr_49,oof_en_49,oof_ridge_49]).transpose()\n",
    "test_stack4 = np.vstack([predictions_br_49, predictions_kr_49,predictions_en_49,predictions_ridge_49]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack4 = np.zeros(train_stack4.shape[0])\n",
    "predictions_lr4 = np.zeros(test_stack4.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack4,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack4[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack4[val_idx], target.iloc[val_idx].values\n",
    "    #LinearRegression\n",
    "    lr4 = lr()\n",
    "    lr4.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack4[val_idx] = lr4.predict(val_data)\n",
    "    predictions_lr4 += lr4.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack4) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Feature Engineering - 383 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.52041441\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_kr_383 = np.zeros(train_shape)\n",
    "predictions_kr_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    kr_383 = kr()\n",
    "    kr_383.fit(tr_x,tr_y)\n",
    "    oof_kr_383[val_idx] = kr_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_kr_383 += kr_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_kr_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.48646216\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_ridge_383 = np.zeros(train_shape)\n",
    "predictions_ridge_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    ridge_383 = Ridge(alpha=1200)\n",
    "    ridge_383.fit(tr_x,tr_y)\n",
    "    oof_ridge_383[val_idx] = ridge_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_ridge_383 += ridge_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_ridge_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.53288151\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_en_383 = np.zeros(train_shape)\n",
    "predictions_en_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    en_383 = en(alpha=1.0,l1_ratio=0.06)\n",
    "    en_383.fit(tr_x,tr_y)\n",
    "    oof_en_383[val_idx] = en_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_en_383 += en_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_en_383, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesianRidge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "fold n°2\n",
      "fold n°3\n",
      "fold n°4\n",
      "fold n°5\n",
      "CV score: 0.48669983\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "oof_br_383 = np.zeros(train_shape)\n",
    "predictions_br_383 = np.zeros(len(X_test_383))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_383, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    tr_x = X_train_383[trn_idx]\n",
    "    tr_y = y_train[trn_idx]\n",
    "    br_383 = br()\n",
    "    br_383.fit(tr_x,tr_y)\n",
    "    oof_br_383[val_idx] = br_383.predict(X_train_383[val_idx])\n",
    "    \n",
    "    predictions_br_383 += br_383.predict(X_test_383) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_br_383, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4874379360552026"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack1 = np.vstack([oof_br_383,oof_kr_383,oof_en_383,oof_ridge_383]).transpose()\n",
    "test_stack1 = np.vstack([predictions_br_383, predictions_kr_383,predictions_en_383,predictions_ridge_383]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack1 = np.zeros(train_stack1.shape[0])\n",
    "predictions_lr1 = np.zeros(test_stack1.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack1,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack1[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack1[val_idx], target.iloc[val_idx].values\n",
    "    # LinearRegression简单的线性回归\n",
    "    lr1 = lr()\n",
    "    lr1.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack1[val_idx] = lr1.predict(val_data)\n",
    "    predictions_lr1 += lr1.predict(test_stack1) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4470118822735938"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stack5 = np.vstack([oof_stack1,oof_stack2,oof_stack3,oof_stack4]).transpose()\n",
    "test_stack5 = np.vstack([predictions_lr1, predictions_lr2,predictions_lr3,predictions_lr4]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=7)\n",
    "oof_stack5 = np.zeros(train_stack5.shape[0])\n",
    "predictions_lr5= np.zeros(test_stack5.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack5,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack5[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack5[val_idx], target.iloc[val_idx].values\n",
    "    #LinearRegression\n",
    "    lr5 = lr()\n",
    "    lr5.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack5[val_idx] = lr5.predict(val_data)\n",
    "    predictions_lr5 += lr5.predict(test_stack5) / 10\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2968.000000\n",
       "mean        3.879260\n",
       "std         0.464408\n",
       "min         1.696071\n",
       "25%         3.661784\n",
       "50%         3.954328\n",
       "75%         4.185904\n",
       "max         5.040234\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_example = pd.read_csv('/Users/Melodie/Downloads/2021Spring/Study/DataWhale/April_Ensembled_Learning/Notes_Ensemble_Learning/Data/case_1/submit_example.csv',sep=',',encoding='latin-1')\n",
    "\n",
    "submit_example['happiness'] = predictions_lr5\n",
    "\n",
    "submit_example.happiness.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2968.000000\n",
       "mean        3.879278\n",
       "std         0.464340\n",
       "min         1.696071\n",
       "25%         3.661784\n",
       "50%         3.954328\n",
       "75%         4.185904\n",
       "max         5.000000\n",
       "Name: happiness, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_example.loc[submit_example['happiness']>4.96,'happiness']= 5\n",
    "submit_example.loc[submit_example['happiness']<=1.04,'happiness']= 1\n",
    "submit_example.loc[(submit_example['happiness']>1.96)&(submit_example['happiness']<2.04),'happiness']= 2\n",
    "\n",
    "submit_example.to_csv(\"/Users/Melodie/Downloads/2021Spring/Study/DataWhale/April_Ensembled_Learning/Notes_Ensemble_Learning/Data/case_1/submision.csv\",index=False)\n",
    "submit_example.happiness.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
